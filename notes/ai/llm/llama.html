<!doctype html>
<html lang="en" dir="ltr" class="docs-wrapper docs-doc-page docs-version-current plugin-docs plugin-id-default docs-doc-id-ai/llm/llama">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v2.2.0">
<title data-rh="true">LLaMa | Wener Live &amp; Life</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:url" content="https://wener.me/notes/ai/llm/llama"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-default-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-default-current"><meta data-rh="true" property="og:title" content="LLaMa | Wener Live &amp; Life"><meta data-rh="true" name="description" content="- LLaMA-7B, 3.5GB, 6GB"><meta data-rh="true" property="og:description" content="- LLaMA-7B, 3.5GB, 6GB"><link data-rh="true" rel="icon" href="/img/favicon.ico"><link data-rh="true" rel="canonical" href="https://wener.me/notes/ai/llm/llama"><link data-rh="true" rel="alternate" href="https://wener.me/notes/ai/llm/llama" hreflang="en"><link data-rh="true" rel="alternate" href="https://wener.me/notes/ai/llm/llama" hreflang="x-default"><link data-rh="true" rel="preconnect" href="https://37P8DMWBKF-dsn.algolia.net" crossorigin="anonymous"><link rel="alternate" type="application/rss+xml" href="/story/rss.xml" title="Wener Live &amp; Life RSS Feed">
<link rel="alternate" type="application/atom+xml" href="/story/atom.xml" title="Wener Live &amp; Life Atom Feed">

<link rel="preconnect" href="https://www.google-analytics.com">
<script>window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)},ga.l=+new Date,ga("create","UA-30404720-1","auto"),ga("send","pageview")</script>
<script async src="https://www.google-analytics.com/analytics.js"></script>
<link rel="preconnect" href="https://www.google-analytics.com">
<link rel="preconnect" href="https://www.googletagmanager.com">
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-30404720-1"></script>
<script>function gtag(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","UA-30404720-1",{})</script>


<link rel="search" type="application/opensearchdescription+xml" title="Wener Live &amp; Life" href="/opensearch.xml">


<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.13.24/dist/katex.min.css">
<script src="https://static.cloudflareinsights.com/beacon.min.js" async data-cf-beacon="{&quot;token&quot;: &quot;e9a1b931103044f3940ee67b78c7df70&quot;}" defer="defer"></script><link rel="stylesheet" href="/assets/css/styles.1c5a76d0.css">
<link rel="preload" href="/assets/js/runtime~main.1619f0f2.js" as="script">
<link rel="preload" href="/assets/js/main.8cb596bc.js" as="script">
</head>
<body class="navigation-with-keyboard">
<script>!function(){function t(t){document.documentElement.setAttribute("data-theme",t)}var e=function(){var t=null;try{t=localStorage.getItem("theme")}catch(t){}return t}();t(null!==e?e:"light")}()</script><div id="__docusaurus">
<div role="region" aria-label="Skip to main content"><a class="skipToContent_GBuj" href="#docusaurus_skipToContent_fallback">Skip to main content</a></div><nav class="navbar navbar--fixed-top"><div class="navbar__inner"><div class="navbar__items"><button aria-label="Toggle navigation bar" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/"><div class="navbar__logo"><img src="/img/wener-logo-head.svg" alt="Wener Logo" class="themedImage_QM0D themedImage--light_s8Fn"><img src="/img/wener-logo-head.svg" alt="Wener Logo" class="themedImage_QM0D themedImage--dark_Yfiw"></div><b class="navbar__title text--truncate">Wener</b></a><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/notes">笔记</a><a class="navbar__item navbar__link" href="/story">故事</a><a class="navbar__item navbar__link" href="/notes/howto/network/dns-prevent-spoofing">指南</a></div><div class="navbar__items navbar__items--right"><a href="https://github.com/wenerme/wener" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">GitHub<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_QEvt"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a><div class="toggle_VZCd colorModeToggle_s_tJ"><button class="clean-btn toggleButton_ubpP toggleButtonDisabled_Okf9" type="button" disabled="" title="Switch between dark and light mode (currently light mode)" aria-label="Switch between dark and light mode (currently light mode)" aria-live="polite"><svg viewBox="0 0 24 24" width="24" height="24" class="lightToggleIcon_Koy5"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" class="darkToggleIcon_vW2_"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg></button></div><div class="searchBox_FlUR"><button type="button" class="DocSearch DocSearch-Button" aria-label="Search"><span class="DocSearch-Button-Container"><svg width="20" height="20" class="DocSearch-Search-Icon" viewBox="0 0 20 20"><path d="M14.386 14.386l4.0877 4.0877-4.0877-4.0877c-2.9418 2.9419-7.7115 2.9419-10.6533 0-2.9419-2.9418-2.9419-7.7115 0-10.6533 2.9418-2.9419 7.7115-2.9419 10.6533 0 2.9419 2.9418 2.9419 7.7115 0 10.6533z" stroke="currentColor" fill="none" fill-rule="evenodd" stroke-linecap="round" stroke-linejoin="round"></path></svg><span class="DocSearch-Button-Placeholder">Search</span></span><span class="DocSearch-Button-Keys"></span></button></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="docusaurus_skipToContent_fallback" class="main-wrapper mainWrapper_Ewau docsWrapper_woa9"><button aria-label="Scroll back to top" class="clean-btn theme-back-to-top-button backToTopButton_T0sX" type="button"></button><div class="docPage_e5SA"><aside class="theme-doc-sidebar-container docSidebarContainer_u9sz"><div class="sidebar_yFJp"><nav class="menu thin-scrollbar menu__KhU"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/notes">笔记</a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--active" aria-expanded="true" href="/notes/ai">AI</a><button aria-label="Toggle the collapsible sidebar category &#x27;AI&#x27;" type="button" class="clean-btn menu__caret"></button></div><ul style="display:block;overflow:visible;height:auto" class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/notes/ai/awesome">AI Awesome</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/notes/ai/faq">AI FAQ</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/notes/ai/glossary">AI Glossary</a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" tabindex="0" href="/notes/ai/chatgpt">ChatGPT</a><button aria-label="Toggle the collapsible sidebar category &#x27;ChatGPT&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/notes/ai/gan">GANs</a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" tabindex="0" href="/notes/ai/gpt">GPT</a><button aria-label="Toggle the collapsible sidebar category &#x27;GPT&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--active" aria-expanded="true" tabindex="0" href="/notes/ai/llm">LLM</a><button aria-label="Toggle the collapsible sidebar category &#x27;LLM&#x27;" type="button" class="clean-btn menu__caret"></button></div><ul style="display:block;overflow:visible;height:auto" class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/notes/ai/llm/alpaca">Alpaca</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link menu__link--active" aria-current="page" tabindex="0" href="/notes/ai/llm/llama">LLaMa</a></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" tabindex="0" href="/notes/ai/ml/deepspeech">ml</a></div></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/notes/ai/model-awesome">Model Awesome</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/notes/ai/ner">Named Entity Recognition</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/notes/ai/openai">OpenAI</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/notes/ai/prompt-awesome">Prompt Awesome</a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" tabindex="0" href="/notes/ai/stable-diffusion">Stable Diffusion</a><button aria-label="Toggle the collapsible sidebar category &#x27;Stable Diffusion&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/notes/ai/whisper">whisper</a></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/notes/algorithm">算法</a><button aria-label="Toggle the collapsible sidebar category &#x27;算法&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/notes/blockchain">区块链</a><button aria-label="Toggle the collapsible sidebar category &#x27;区块链&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/notes/courses">课程</a><button aria-label="Toggle the collapsible sidebar category &#x27;课程&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/notes/culture">文化</a><button aria-label="Toggle the collapsible sidebar category &#x27;文化&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/notes/db">数据库</a><button aria-label="Toggle the collapsible sidebar category &#x27;数据库&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/notes/design">设计</a><button aria-label="Toggle the collapsible sidebar category &#x27;设计&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/notes/dev">开发</a><button aria-label="Toggle the collapsible sidebar category &#x27;开发&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/notes/devops">DevOps</a><button aria-label="Toggle the collapsible sidebar category &#x27;DevOps&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/notes/economics">经济学</a><button aria-label="Toggle the collapsible sidebar category &#x27;经济学&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" href="/notes/elastic/elasticsearch-v2">elastic</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" href="/notes/electrical/glossary">electrical</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" href="/notes/embedded/awesome">embedded</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/notes/evolve">自我成长</a><button aria-label="Toggle the collapsible sidebar category &#x27;自我成长&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/notes/game">游戏</a><button aria-label="Toggle the collapsible sidebar category &#x27;游戏&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/notes/hardware">硬件</a><button aria-label="Toggle the collapsible sidebar category &#x27;硬件&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/notes/healthcare">健康</a><button aria-label="Toggle the collapsible sidebar category &#x27;健康&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" href="/notes/howto/network/dns-prevent-spoofing">howto</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/notes/java">Java</a><button aria-label="Toggle the collapsible sidebar category &#x27;Java&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/notes/languages">语言</a><button aria-label="Toggle the collapsible sidebar category &#x27;语言&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/notes/mgmt">管理</a><button aria-label="Toggle the collapsible sidebar category &#x27;管理&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" href="/notes/network/application/dns">network</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/notes/ops">运维</a><button aria-label="Toggle the collapsible sidebar category &#x27;运维&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/notes/os">操作系统</a><button aria-label="Toggle the collapsible sidebar category &#x27;操作系统&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" href="/notes/philosophy/faq">philosophy</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/notes/photography">摄影</a><button aria-label="Toggle the collapsible sidebar category &#x27;摄影&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/notes/platform">平台</a><button aria-label="Toggle the collapsible sidebar category &#x27;平台&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/notes/queue">Queue</a><button aria-label="Toggle the collapsible sidebar category &#x27;Queue&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" href="/notes/reference/cook/glossary">reference</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/notes/security">安全</a><button aria-label="Toggle the collapsible sidebar category &#x27;安全&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/notes/service">服务</a><button aria-label="Toggle the collapsible sidebar category &#x27;服务&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/notes/tool">工具</a><button aria-label="Toggle the collapsible sidebar category &#x27;工具&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/notes/voip">VoIP</a><button aria-label="Toggle the collapsible sidebar category &#x27;VoIP&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/notes/web">Web</a><button aria-label="Toggle the collapsible sidebar category &#x27;Web&#x27;" type="button" class="clean-btn menu__caret"></button></div></li></ul></nav><button type="button" title="Collapse sidebar" aria-label="Collapse sidebar" class="button button--secondary button--outline collapseSidebarButton_jgTA"><svg width="20" height="20" aria-hidden="true" class="collapseSidebarButtonIcon_tDu3"><g fill="#7a7a7a"><path d="M9.992 10.023c0 .2-.062.399-.172.547l-4.996 7.492a.982.982 0 01-.828.454H1c-.55 0-1-.453-1-1 0-.2.059-.403.168-.551l4.629-6.942L.168 3.078A.939.939 0 010 2.528c0-.548.45-.997 1-.997h2.996c.352 0 .649.18.828.45L9.82 9.472c.11.148.172.347.172.55zm0 0"></path><path d="M19.98 10.023c0 .2-.058.399-.168.547l-4.996 7.492a.987.987 0 01-.828.454h-3c-.547 0-.996-.453-.996-1 0-.2.059-.403.168-.551l4.625-6.942-4.625-6.945a.939.939 0 01-.168-.55 1 1 0 01.996-.997h3c.348 0 .649.18.828.45l4.996 7.492c.11.148.168.347.168.55zm0 0"></path></g></svg></button></div></aside><main class="docMainContainer_jz8z"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_CixA"><div class="docItemContainer_zckq"><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_FBYY" aria-label="Breadcrumbs"><ul class="breadcrumbs" itemscope="" itemtype="https://schema.org/BreadcrumbList"><li class="breadcrumbs__item"><a aria-label="Home page" class="breadcrumbs__link" href="/"><svg viewBox="0 0 24 24" class="breadcrumbHomeIcon_jnrL"><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill="currentColor"></path></svg></a></li><li itemscope="" itemprop="itemListElement" itemtype="https://schema.org/ListItem" class="breadcrumbs__item"><a class="breadcrumbs__link" itemprop="item" href="/notes/ai"><span itemprop="name">AI</span></a><meta itemprop="position" content="1"></li><li itemscope="" itemprop="itemListElement" itemtype="https://schema.org/ListItem" class="breadcrumbs__item"><a class="breadcrumbs__link" itemprop="item" href="/notes/ai/llm"><span itemprop="name">LLM</span></a><meta itemprop="position" content="2"></li><li itemscope="" itemprop="itemListElement" itemtype="https://schema.org/ListItem" class="breadcrumbs__item breadcrumbs__item--active"><span class="breadcrumbs__link" itemprop="name">LLaMa</span><meta itemprop="position" content="3"></li></ul></nav><div class="tocCollapsible_MiWk theme-doc-toc-mobile tocMobile_dcUs"><button type="button" class="clean-btn tocCollapsibleButton_Bqtn">On this page</button></div><div class="theme-doc-markdown markdown"><h1>llama</h1><ul><li>LLaMA-7B, 3.5GB, 6GB</li><li>LLaMA-13B, 6.5GB, 10GB</li><li>LLaMA-30B, 15.8GB, 20GB</li><li>LLaMA-65B, 31.2GB, 40GB</li><li><a href="https://news.ycombinator.com/item?id=35107058" target="_blank" rel="noopener noreferrer">https://news.ycombinator.com/item?id=35107058</a></li><li><a href="https://github.com/ZrrSkywalker/LLaMA-Adapter" target="_blank" rel="noopener noreferrer">https://github.com/ZrrSkywalker/LLaMA-Adapter</a></li><li><a href="https://huggingface.co/blog/stackllama" target="_blank" rel="noopener noreferrer">https://huggingface.co/blog/stackllama</a></li></ul><div class="language-bash codeBlockContainer_eErV theme-code-block" style="--prism-color:#bfc7d5;--prism-background-color:#292d3e"><div class="codeBlockContent_UzAP"><pre tabindex="0" class="prism-code language-bash codeBlock_CYhB thin-scrollbar"><code class="codeBlockLines__AHC"><span class="token-line" style="color:#bfc7d5"><span class="token comment" style="color:rgb(105, 112, 152);font-style:italic"># py for</span><span class="token plain"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">apk </span><span class="token function" style="color:rgb(130, 170, 255)">add</span><span class="token plain"> </span><span class="token punctuation" style="color:rgb(199, 146, 234)">\</span><span class="token plain"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">  gcc g++ python3 py3-pip musl-dev cmake </span><span class="token function" style="color:rgb(130, 170, 255)">make</span><span class="token plain"> pkgconf build-base </span><span class="token punctuation" style="color:rgb(199, 146, 234)">\</span><span class="token plain"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">  </span><span class="token function" style="color:rgb(130, 170, 255)">git</span><span class="token plain"> openssh-client binutils coreutils util-linux findutils </span><span class="token function" style="color:rgb(130, 170, 255)">sed</span><span class="token plain"> </span><span class="token function" style="color:rgb(130, 170, 255)">grep</span><span class="token plain"> </span><span class="token function" style="color:rgb(130, 170, 255)">tar</span><span class="token plain"> </span><span class="token function" style="color:rgb(130, 170, 255)">wget</span><span class="token plain"> </span><span class="token function" style="color:rgb(130, 170, 255)">curl</span><span class="token plain"> neofetch </span><span class="token punctuation" style="color:rgb(199, 146, 234)">\</span><span class="token plain"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">  rust cargo python3-dev openssl-dev linux-headers</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"></span><span class="token comment" style="color:rgb(105, 112, 152);font-style:italic"># llama.cpp</span><span class="token plain"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"></span><span class="token comment" style="color:rgb(105, 112, 152);font-style:italic"># =========</span><span class="token plain"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"></span><span class="token function" style="color:rgb(130, 170, 255)">git</span><span class="token plain"> clone https://github.com/ggerganov/llama.cpp.git</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"></span><span class="token builtin class-name" style="color:rgb(255, 203, 107)">cd</span><span class="token plain"> llama.cpp</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"></span><span class="token function" style="color:rgb(130, 170, 255)">make</span><span class="token plain"> -j</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">./main -m ./models/7B/ggml-model-q4_0.bin -p </span><span class="token string" style="color:rgb(195, 232, 141)">&quot;Building a website can be done in 10 simple steps:&quot;</span><span class="token plain"> -n </span><span class="token number" style="color:rgb(247, 140, 108)">512</span><span class="token plain"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">./main -m ./models/7B/ggml-model-q4_0.bin --file prompts/alpaca.txt --instruct --ctx_size </span><span class="token number" style="color:rgb(247, 140, 108)">2048</span><span class="token plain"> --keep -1</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">./main -m ./models/ggml-alpaca-7b-q4.bin --color -f ./prompts/alpaca.txt -ins -b </span><span class="token number" style="color:rgb(247, 140, 108)">256</span><span class="token plain"> --top_k </span><span class="token number" style="color:rgb(247, 140, 108)">10000</span><span class="token plain"> --temp </span><span class="token number" style="color:rgb(247, 140, 108)">0.2</span><span class="token plain"> --repeat_penalty </span><span class="token number" style="color:rgb(247, 140, 108)">1</span><span class="token plain"> -t </span><span class="token number" style="color:rgb(247, 140, 108)">7</span><span class="token plain"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"></span><span class="token comment" style="color:rgb(105, 112, 152);font-style:italic"># https://github.com/ymcui/Chinese-LLaMA-Alpaca</span><span class="token plain"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"></span><span class="token comment" style="color:rgb(105, 112, 152);font-style:italic"># =========</span><span class="token plain"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">apk </span><span class="token function" style="color:rgb(130, 170, 255)">add</span><span class="token plain"> rust cargo python3-dev openssl-dev cmake linux-headers</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">pip </span><span class="token function" style="color:rgb(130, 170, 255)">install</span><span class="token plain"> git+https://github.com/huggingface/transformers</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">pip </span><span class="token function" style="color:rgb(130, 170, 255)">install</span><span class="token plain"> sentencepiece</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">pip </span><span class="token function" style="color:rgb(130, 170, 255)">install</span><span class="token plain"> torch --index-url https://download.pytorch.org/whl/cpu</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">pip </span><span class="token function" style="color:rgb(130, 170, 255)">install</span><span class="token plain"> peft</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"></span><span class="token function" style="color:rgb(130, 170, 255)">git</span><span class="token plain"> clone https://github.com/huggingface/transformers</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"></span><span class="token comment" style="color:rgb(105, 112, 152);font-style:italic"># musl pthread_attr_setaffinity_np</span><span class="token plain"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">python ./transformers/src/transformers/models/llama/convert_llama_weights_to_hf.py </span><span class="token punctuation" style="color:rgb(199, 146, 234)">\</span><span class="token plain"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">  --input_dir /ml/models/LLaMA </span><span class="token punctuation" style="color:rgb(199, 146, 234)">\</span><span class="token plain"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">  --model_size 7B </span><span class="token punctuation" style="color:rgb(199, 146, 234)">\</span><span class="token plain"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">  --output_dir /ml/models/LLaMA-hf</span><br></span></code></pre><div class="buttonGroup_tnuT"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_tmcC" aria-hidden="true"><svg class="copyButtonIcon_Azkd" viewBox="0 0 24 24"><path d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg class="copyButtonSuccessIcon_pt5v" viewBox="0 0 24 24"><path d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><hr><ul><li><a href="https://rentry.org/lmg_models" target="_blank" rel="noopener noreferrer">https://rentry.org/lmg_models</a></li></ul><p>#-&gt;/lmg/ Model Links and Torrents &lt;-</p><p>[TOC2]</p><h2 class="anchor anchorWithStickyNavbar_KJCY" id="changelog-mdy">Changelog (MDY)<a class="hash-link" href="#changelog-mdy" title="Direct link to heading">​</a></h2><p>[05-10-2023]<!-- --> - Added WizardLM 13B Uncensored
<!-- -->[05-07-2023]<!-- --> - Added Vicuna 13B Cocktail, bluemoonrp-13b &amp; AlpacaDente2
<!-- -->[05-05-2023]<!-- --> - Added CPU quantization variation links
<!-- -->[05-02-2023]<!-- --> - Initial Rentry</p><h2 class="anchor anchorWithStickyNavbar_KJCY" id="4-bit-gpu-model-requirements">4-bit GPU Model Requirements<a class="hash-link" href="#4-bit-gpu-model-requirements" title="Direct link to heading">​</a></h2><p>!!! note VRAM Required takes full context (2048) into account. You may be able to load the model on GPU&#x27;s with slightly lower VRAM, but you will not be able to run at full context. If you do not have enough RAM to load model, it will load into swap. Groupsize models will increase VRAM usage, as will running a LoRA alongside the model.</p><table><thead><tr><th>Model Parameters</th><th>VRAM Required</th><th>GPU Examples</th><th>RAM to Load</th></tr></thead><tbody><tr><td>7B</td><td>8GB</td><td>RTX 1660, 2060, AMD 5700xt, RTX 3050, RTX 3060, RTX 3070</td><td>6 GB</td></tr><tr><td>13B</td><td>12GB</td><td>AMD 6900xt, RTX 2060 12GB, 3060 12GB, 3080 12GB, A2000</td><td>12GB</td></tr><tr><td>30B</td><td>24GB</td><td>RTX 3090, RTX 4090, A4500, A5000, 6000, Tesla V100</td><td>32GB</td></tr><tr><td>65B</td><td>42GB</td><td>A100 80GB, NVIDIA Quadro RTX 8000, Quadro RTX A6000</td><td>64GB</td></tr></tbody></table><h2 class="anchor anchorWithStickyNavbar_KJCY" id="4-bit-cpullamacpp-ram-requirements">4-bit CPU/llama.cpp RAM Requirements<a class="hash-link" href="#4-bit-cpullamacpp-ram-requirements" title="Direct link to heading">​</a></h2><p>!!! note 5bit to 8bit Quantized models are becoming more common, and will obviously require more RAM. Will update these with the numbers when I have them.</p><table><thead><tr><th>Model</th><th>4-bit</th><th>5-bit</th><th>8-bit</th></tr></thead><tbody><tr><td>7B</td><td>3.9 GB</td><td></td><td></td></tr><tr><td>13B</td><td>7.8 GB</td><td></td><td></td></tr><tr><td>30B</td><td>19.5 GB</td><td></td><td></td></tr><tr><td>65B</td><td>38.5 GB</td><td></td><td></td></tr></tbody></table><h1>Original Weights</h1><h2 class="anchor anchorWithStickyNavbar_KJCY" id="llama-16-bit-weights">LLaMA 16-bit Weights<a class="hash-link" href="#llama-16-bit-weights" title="Direct link to heading">​</a></h2><p>!!! info</p><div class="codeBlockContainer_eErV theme-code-block" style="--prism-color:#bfc7d5;--prism-background-color:#292d3e"><div class="codeBlockContent_UzAP"><pre tabindex="0" class="prism-code language-text codeBlock_CYhB thin-scrollbar"><code class="codeBlockLines__AHC"><span class="token-line" style="color:#bfc7d5"><span class="token plain">The original LLaMA weights converted to Transformers @ 16bit. A torrent is available as well, but it uses outdated configuration files that will need to be updated. Note that these aren&#x27;t for general use, as the VRAM requirements are beyond consumer scope.</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">&gt;Filtering : None</span><br></span></code></pre><div class="buttonGroup_tnuT"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_tmcC" aria-hidden="true"><svg class="copyButtonIcon_Azkd" viewBox="0 0 24 24"><path d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg class="copyButtonSuccessIcon_pt5v" viewBox="0 0 24 24"><path d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><table><thead><tr><th>Model</th><th>Type</th><th>Download</th></tr></thead><tbody><tr><td>7B 16bit</td><td>HF Format</td><td><a href="https://huggingface.co/Neko-Institute-of-Science/LLaMA-7B-HF" target="_blank" rel="noopener noreferrer">HuggingFace</a></td></tr><tr><td>13B 16bit</td><td>HF Format</td><td><a href="https://huggingface.co/Neko-Institute-of-Science/LLaMA-13B-HF" target="_blank" rel="noopener noreferrer">HuggingFace</a></td></tr><tr><td>30B 16bit</td><td>HF Format</td><td><a href="https://huggingface.co/Neko-Institute-of-Science/LLaMA-30B-HF" target="_blank" rel="noopener noreferrer">HuggingFace</a></td></tr><tr><td>65B 16bit</td><td>HF Format</td><td><a href="https://huggingface.co/Neko-Institute-of-Science/LLaMA-13B-HF" target="_blank" rel="noopener noreferrer">HuggingFace</a></td></tr><tr><td>All the above</td><td>HF Format</td><td><a href="magnet:?xt=urn:btih:8d634925911a03f787d9f68ac075a9b24281573a&amp;dn=Safe-LLaMA-HF-v2%20(4-04-23)&amp;tr=http%3a%2f%2fbt2.archive.org%3a6969%2fannounce&amp;tr=http%3a%2f%2fbt1.archive.org%3a6969%2fannounce" target="_blank" rel="noopener noreferrer">Torrent Magnet</a></td></tr></tbody></table><h2 class="anchor anchorWithStickyNavbar_KJCY" id="llama-4-bit-weights">LLaMA 4-bit Weights<a class="hash-link" href="#llama-4-bit-weights" title="Direct link to heading">​</a></h2><p>!!! info</p><div class="codeBlockContainer_eErV theme-code-block" style="--prism-color:#bfc7d5;--prism-background-color:#292d3e"><div class="codeBlockContent_UzAP"><pre tabindex="0" class="prism-code language-text codeBlock_CYhB thin-scrollbar"><code class="codeBlockLines__AHC"><span class="token-line" style="color:#bfc7d5"><span class="token plain">The original LLaMA weights quantized to 4-bit. The GPU CUDA versions have outdated tokenizer and configuration files. It is recommended to either update them with [this](https://rentry.org/544p2) or use the [universal LLaMA tokenizer.](https://github.com/oobabooga/text-generation-webui/blob/main/docs/LLaMA-model.md#option-1-pre-converted-weights)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">&gt;Filtering : None</span><br></span></code></pre><div class="buttonGroup_tnuT"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_tmcC" aria-hidden="true"><svg class="copyButtonIcon_Azkd" viewBox="0 0 24 24"><path d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg class="copyButtonSuccessIcon_pt5v" viewBox="0 0 24 24"><path d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><table><thead><tr><th>Model</th><th>Type</th><th>Download</th></tr></thead><tbody><tr><td>7B, 13B, 30B, 65B</td><td>CPU</td><td><a href="magnet:?xt=urn:btih:481dee5424b7024433504803a90efd32dae40fdf&amp;dn=LLaMA-ggml-4bit_2023-03-31&amp;tr=udp%3a%2f%2ftracker1.bt.moack.co.kr%3a80%2fannounce&amp;tr=udp%3a%2f%2ftracker.torrent.eu.org%3a451%2fannounce&amp;tr=udp%3a%2f%2ftracker.altrosky.nl%3a6969%2fannounce&amp;tr=udp%3a%2f%2fopentracker.i2p.rocks%3a6969%2fannounce&amp;tr=udp%3a%2f%2ftracker.opentrackr.org%3a1337%2fannounce&amp;tr=https%3a%2f%2fopentracker.i2p.rocks%3a443%2fannounce&amp;tr=udp%3a%2f%2ftracker.theoks.net%3a6969%2fannounce&amp;tr=udp%3a%2f%2ftracker-udp.gbitt.info%3a80%2fannounce&amp;tr=udp%3a%2f%2ftracker.tiny-vps.com%3a6969%2fannounce&amp;tr=udp%3a%2f%2ftracker.moeking.me%3a6969%2fannounce&amp;tr=udp%3a%2f%2f9.rarbg.com%3a2810%2fannounce&amp;tr=udp%3a%2f%2ftracker.openbittorrent.com%3a6969%2fannounce&amp;tr=udp%3a%2f%2ftracker.monitorit4.me%3a6969%2fannounce&amp;tr=udp%3a%2f%2ftracker.dler.org%3a6969%2fannounce&amp;tr=http%3a%2f%2ftracker.openbittorrent.com%3a80%2fannounce&amp;tr=udp%3a%2f%2ftracker2.dler.org%3a80%2fannounce" target="_blank" rel="noopener noreferrer">Torrent Magnet</a></td></tr><tr><td>7B, 13B, 30B, 65B</td><td>GPU CUDA (no groupsize)</td><td><a href="magnet:?xt=urn:btih:e88abf1b84290b162f00d3a9d79fb4f8719c2053&amp;dn=LLaMA-HF-4bit&amp;tr=http%3a%2f%2fbt2.archive.org%3a6969%2fannounce&amp;tr=http%3a%2f%2fbt1.archive.org%3a6969%2fannounce" target="_blank" rel="noopener noreferrer">Torrent Magnet</a></td></tr><tr><td>7B, 13B, 30B, 65B</td><td>GPU CUDA (128gs)</td><td><a href="magnet:?xt=urn:btih:88f7d9d2460ffcaf78b21e83012de00939eacb65&amp;dn=LLaMA-HF-4bit-128g&amp;tr=http%3a%2f%2fbt2.archive.org%3a6969%2fannounce&amp;tr=http%3a%2f%2fbt1.archive.org%3a6969%2fannounce" target="_blank" rel="noopener noreferrer">Torrent Magnet</a></td></tr><tr><td>7B, 13B, 30B, 65B</td><td>GPU Triton</td><td><a href="https://huggingface.co/Neko-Institute-of-Science" target="_blank" rel="noopener noreferrer">Neko Institute of Science HF page</a></td></tr></tbody></table><h1>Models/Finetunes/LoRA&#x27;s</h1><h2 class="anchor anchorWithStickyNavbar_KJCY" id="wizardlm-13b-uncensored-05102023">WizardLM 13B Uncensored (05/10/2023)<a class="hash-link" href="#wizardlm-13b-uncensored-05102023" title="Direct link to heading">​</a></h2><p>!!! info</p><div class="codeBlockContainer_eErV theme-code-block" style="--prism-color:#bfc7d5;--prism-background-color:#292d3e"><div class="codeBlockContent_UzAP"><pre tabindex="0" class="prism-code language-text codeBlock_CYhB thin-scrollbar"><code class="codeBlockLines__AHC"><span class="token-line" style="color:#bfc7d5"><span class="token plain">This is WizardLM trained with a subset of the dataset - responses that contained alignment / moralizing were removed. The intent is to train a WizardLM that doesn&#x27;t have alignment built-in, so that alignment (of any sort) can be added separately with for example with a RLHF LoRA.</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">Note that despite being an &quot;uncensored&quot; model, several tests have demonstrated that the model will still refuse to comply with certain requests.</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">&gt;Filtering : Light</span><br></span></code></pre><div class="buttonGroup_tnuT"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_tmcC" aria-hidden="true"><svg class="copyButtonIcon_Azkd" viewBox="0 0 24 24"><path d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg class="copyButtonSuccessIcon_pt5v" viewBox="0 0 24 24"><path d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><table><thead><tr><th>Model</th><th>Type</th><th>Download</th></tr></thead><tbody><tr><td>13B GGML</td><td>CPU</td><td><a href="https://huggingface.co/TehVenom/WizardLM-13B-Uncensored-Q5_1-GGML" target="_blank" rel="noopener noreferrer">Q5</a></td></tr><tr><td>13B</td><td>GPU</td><td><a href="https://huggingface.co/ausboss/WizardLM-13B-Uncensored-4bit-128g" target="_blank" rel="noopener noreferrer">Q4 CUDA 128gs</a></td></tr></tbody></table><h2 class="anchor anchorWithStickyNavbar_KJCY" id="bluemoonrp-13b-05072023">BluemoonRP 13B (05/07/2023)<a class="hash-link" href="#bluemoonrp-13b-05072023" title="Direct link to heading">​</a></h2><p>!!! info</p><div class="codeBlockContainer_eErV theme-code-block" style="--prism-color:#bfc7d5;--prism-background-color:#292d3e"><div class="codeBlockContent_UzAP"><pre tabindex="0" class="prism-code language-text codeBlock_CYhB thin-scrollbar"><code class="codeBlockLines__AHC"><span class="token-line" style="color:#bfc7d5"><span class="token plain">An RP/ERP focused finetune of LLaMA 13B finetuned on BluemoonRP logs. It is designed to simulate a 2-person RP session. Two versions are provided; a standard 13B with 2K context and an experimental 13B with 4K context. It has a non-standard format (LEAD/ASSOCIATE), so ensure that you read the model card and use the correct syntax.</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">&gt;Filtering : None</span><br></span></code></pre><div class="buttonGroup_tnuT"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_tmcC" aria-hidden="true"><svg class="copyButtonIcon_Azkd" viewBox="0 0 24 24"><path d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg class="copyButtonSuccessIcon_pt5v" viewBox="0 0 24 24"><path d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><table><thead><tr><th>Model</th><th>Type</th><th>Download</th></tr></thead><tbody><tr><td>13B</td><td>GPU &amp; CPU</td><td><a href="https://huggingface.co/reeducator/bluemoonrp-13b" target="_blank" rel="noopener noreferrer">https://huggingface.co/reeducator/bluemoonrp-13b</a></td></tr></tbody></table><h2 class="anchor anchorWithStickyNavbar_KJCY" id="vicuna-13b-cocktail-05072023">Vicuna 13B Cocktail (05/07/2023)<a class="hash-link" href="#vicuna-13b-cocktail-05072023" title="Direct link to heading">​</a></h2><p>!!! info</p><div class="codeBlockContainer_eErV theme-code-block" style="--prism-color:#bfc7d5;--prism-background-color:#292d3e"><div class="codeBlockContent_UzAP"><pre tabindex="0" class="prism-code language-text codeBlock_CYhB thin-scrollbar"><code class="codeBlockLines__AHC"><span class="token-line" style="color:#bfc7d5"><span class="token plain">Vicuna 1.1 13B finetune incorporating various datasets in addition to the unfiltered ShareGPT. This is an experiment attempting to enhance the creativity of the Vicuna 1.1, while also reducing censorship as much as possible. All datasets have been cleaned. Additionally, only the &quot;instruct&quot; portion of GPTeacher has been used. It has a non-standard format (USER/ASSOCIATE), so ensure that you read the model card and use the correct syntax.</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">&gt;Filtering : Light</span><br></span></code></pre><div class="buttonGroup_tnuT"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_tmcC" aria-hidden="true"><svg class="copyButtonIcon_Azkd" viewBox="0 0 24 24"><path d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg class="copyButtonSuccessIcon_pt5v" viewBox="0 0 24 24"><path d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><table><thead><tr><th>Model</th><th>Type</th><th>Download</th></tr></thead><tbody><tr><td>13B</td><td>GPU &amp; CPU</td><td><a href="https://huggingface.co/reeducator/vicuna-13b-cocktail" target="_blank" rel="noopener noreferrer">https://huggingface.co/reeducator/vicuna-13b-cocktail</a></td></tr></tbody></table><h2 class="anchor anchorWithStickyNavbar_KJCY" id="gpt4-x-alpacadente2-30b-05052023">GPT4-x-AlpacaDente2-30B (05/05/2023)<a class="hash-link" href="#gpt4-x-alpacadente2-30b-05052023" title="Direct link to heading">​</a></h2><p>!!! info</p><div class="codeBlockContainer_eErV theme-code-block" style="--prism-color:#bfc7d5;--prism-background-color:#292d3e"><div class="codeBlockContent_UzAP"><pre tabindex="0" class="prism-code language-text codeBlock_CYhB thin-scrollbar"><code class="codeBlockLines__AHC"><span class="token-line" style="color:#bfc7d5"><span class="token plain">ChanSung&#x27;s Alpaca-LoRA-30B-elina merged with Open Assistant&#x27;s second Finetune. Testing in progress.</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">&gt;Filtering : Medium</span><br></span></code></pre><div class="buttonGroup_tnuT"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_tmcC" aria-hidden="true"><svg class="copyButtonIcon_Azkd" viewBox="0 0 24 24"><path d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg class="copyButtonSuccessIcon_pt5v" viewBox="0 0 24 24"><path d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><table><thead><tr><th>Model</th><th>Type</th><th>Download</th></tr></thead><tbody><tr><td>30B GGML</td><td>CPU</td><td><a href="https://huggingface.co/Lumpen1/GPT4-x-AlpacaDente2-30b-ggml-q5_0" target="_blank" rel="noopener noreferrer">Q5</a></td></tr><tr><td>30B</td><td>GPU</td><td><a href="https://huggingface.co/askmyteapot/GPT4-x-AlpacaDente2-30b-4bit" target="_blank" rel="noopener noreferrer">Q4 CUDA</a></td></tr></tbody></table><p><a href="https://huggingface.co/askmyteapot/GPT4-x-AlpacaDente2-30b-4bit" target="_blank" rel="noopener noreferrer">https://huggingface.co/askmyteapot/GPT4-x-AlpacaDente2-30b-4bit</a></p><h2 class="anchor anchorWithStickyNavbar_KJCY" id="vicuna-13b-free-v11-05012023">Vicuna 13B Free v1.1 (05/01/2023)<a class="hash-link" href="#vicuna-13b-free-v11-05012023" title="Direct link to heading">​</a></h2><p>!!! info</p><div class="codeBlockContainer_eErV theme-code-block" style="--prism-color:#bfc7d5;--prism-background-color:#292d3e"><div class="codeBlockContent_UzAP"><pre tabindex="0" class="prism-code language-text codeBlock_CYhB thin-scrollbar"><code class="codeBlockLines__AHC"><span class="token-line" style="color:#bfc7d5"><span class="token plain">A work-in-progress, community driven attempt to make an unfiltered version of Vicuna. It currently has an early stopping bug, and a partial workaround has been posted on the repo&#x27;s model card.</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">&gt;Filtering : Light</span><br></span></code></pre><div class="buttonGroup_tnuT"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_tmcC" aria-hidden="true"><svg class="copyButtonIcon_Azkd" viewBox="0 0 24 24"><path d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg class="copyButtonSuccessIcon_pt5v" viewBox="0 0 24 24"><path d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><table><thead><tr><th>Model</th><th>Type</th><th>Download</th></tr></thead><tbody><tr><td>13B</td><td>GPU &amp; CPU</td><td><a href="https://huggingface.co/reeducator/vicuna-13b-free" target="_blank" rel="noopener noreferrer">https://huggingface.co/reeducator/vicuna-13b-free</a></td></tr></tbody></table><h2 class="anchor anchorWithStickyNavbar_KJCY" id="pygmalionmetharme-7b-04302023">Pygmalion/Metharme 7B (04/30/2023)<a class="hash-link" href="#pygmalionmetharme-7b-04302023" title="Direct link to heading">​</a></h2><p>!!! info</p><div class="codeBlockContainer_eErV theme-code-block" style="--prism-color:#bfc7d5;--prism-background-color:#292d3e"><div class="codeBlockContent_UzAP"><pre tabindex="0" class="prism-code language-text codeBlock_CYhB thin-scrollbar"><code class="codeBlockLines__AHC"><span class="token-line" style="color:#bfc7d5"><span class="token plain">Pygmalion 7B is a dialogue model that uses LLaMA-7B as a base. The dataset includes RP/ERP content. Metharme 7B is an experimental instruct-tuned variation, which can be guided using natural language like other instruct models.</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">PygmalionAI intend to use the same dataset on the higher parameter LLaMA models. No ETA as of yet.</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">&gt;Filtering : None</span><br></span></code></pre><div class="buttonGroup_tnuT"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_tmcC" aria-hidden="true"><svg class="copyButtonIcon_Azkd" viewBox="0 0 24 24"><path d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg class="copyButtonSuccessIcon_pt5v" viewBox="0 0 24 24"><path d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><table><thead><tr><th>Model</th><th>Type</th><th>Download</th></tr></thead><tbody><tr><td>7B Pygmalion/Metharme</td><td>XOR</td><td><a href="https://huggingface.co/PygmalionAI/" target="_blank" rel="noopener noreferrer">https://huggingface.co/PygmalionAI/</a></td></tr><tr><td>7B Pygmalion GGML</td><td>CPU</td><td><a href="https://huggingface.co/TehVenom/Pygmalion-7b-4bit-Q4_1-GGML" target="_blank" rel="noopener noreferrer">Q4</a>, <a href="https://huggingface.co/waifu-workshop/pygmalion-7b-ggml-q5_0" target="_blank" rel="noopener noreferrer">Q5</a>, <a href="https://huggingface.co/waifu-workshop/pygmalion-7b-ggml-q8_0" target="_blank" rel="noopener noreferrer">Q8</a></td></tr><tr><td>7B Metharme GGML</td><td>CPU</td><td><a href="https://huggingface.co/TehVenom/Metharme-7b-4bit-Q4_1-GGML" target="_blank" rel="noopener noreferrer">Q4</a>, <a href="https://huggingface.co/waifu-workshop/metharme-7b-ggml-q5_1" target="_blank" rel="noopener noreferrer">Q5</a></td></tr><tr><td>7B Pygmalion</td><td>GPU</td><td><a href="https://huggingface.co/TehVenom/Pygmalion-7b-4bit-GPTQ-Safetensors" target="_blank" rel="noopener noreferrer">Q4 Triton</a>, <a href="https://huggingface.co/gozfarb/pygmalion-7b-4bit-128g-cuda" target="_blank" rel="noopener noreferrer">Q4 CUDA 128gs</a></td></tr><tr><td>7B Metharme</td><td>GPU</td><td><a href="https://huggingface.co/TehVenom/Metharme-7b-4bit-GPTQ-Safetensors" target="_blank" rel="noopener noreferrer">Q4 Triton</a>, <a href="https://huggingface.co/askmyteapot/metharme" target="_blank" rel="noopener noreferrer">Q4 CUDA</a></td></tr></tbody></table><h2 class="anchor anchorWithStickyNavbar_KJCY" id="gpt4-x-alpasta-30b-04292023">GPT4-X-Alpasta 30B (04/29/2023)<a class="hash-link" href="#gpt4-x-alpasta-30b-04292023" title="Direct link to heading">​</a></h2><p>!!! info</p><div class="codeBlockContainer_eErV theme-code-block" style="--prism-color:#bfc7d5;--prism-background-color:#292d3e"><div class="codeBlockContent_UzAP"><pre tabindex="0" class="prism-code language-text codeBlock_CYhB thin-scrollbar"><code class="codeBlockLines__AHC"><span class="token-line" style="color:#bfc7d5"><span class="token plain">An attempt at improving Open Assistant&#x27;s performance as an instruct while retaining its excellent prose. The merge consists of Chansung&#x27;s GPT4-Alpaca Lora and Open Assistant&#x27;s native fine-tune.</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">It is an extremely coherent model for logic based instruct outputs. And while the prose is generally very good, it does suffer from the &quot;Assistant&quot; personality bleedthrough that plagues the OpenAssistant dataset, which can give you dry dialogue for creative writing/chatbot purposes. However, several accounts claim it&#x27;s nowhere near as bad as OA&#x27;s finetunes, and that the prose and coherence gains makes up for it.</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">&gt;Filtering : Medium</span><br></span></code></pre><div class="buttonGroup_tnuT"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_tmcC" aria-hidden="true"><svg class="copyButtonIcon_Azkd" viewBox="0 0 24 24"><path d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg class="copyButtonSuccessIcon_pt5v" viewBox="0 0 24 24"><path d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><table><thead><tr><th>Model</th><th>Type</th><th>Download</th></tr></thead><tbody><tr><td>30B 4bit</td><td>CPU &amp; GPU CUDA</td><td><a href="https://huggingface.co/MetaIX/GPT4-X-Alpasta-30b-4bit" target="_blank" rel="noopener noreferrer">https://huggingface.co/MetaIX/GPT4-X-Alpasta-30b-4bit</a></td></tr></tbody></table><h2 class="anchor anchorWithStickyNavbar_KJCY" id="openassistant-llama-30b-sft-6-04232023">OpenAssistant LLaMa 30B SFT 6 (04/23/2023)<a class="hash-link" href="#openassistant-llama-30b-sft-6-04232023" title="Direct link to heading">​</a></h2><p>!!! info</p><div class="codeBlockContainer_eErV theme-code-block" style="--prism-color:#bfc7d5;--prism-background-color:#292d3e"><div class="codeBlockContent_UzAP"><pre tabindex="0" class="prism-code language-text codeBlock_CYhB thin-scrollbar"><code class="codeBlockLines__AHC"><span class="token-line" style="color:#bfc7d5"><span class="token plain">An open-source alternative to OpenAI’s ChatGPT/GPT 3.5 Turbo. However, it seems to suffer from [overfitting](https://www.datarobot.com/wiki/overfitting/) and is heavily filtered. Not recommended for creative writing or chat bots, given the &quot;assistant&quot; personality constantly bleeds through, giving you dry dialogue.</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">&gt;Filtering : Heavy</span><br></span></code></pre><div class="buttonGroup_tnuT"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_tmcC" aria-hidden="true"><svg class="copyButtonIcon_Azkd" viewBox="0 0 24 24"><path d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg class="copyButtonSuccessIcon_pt5v" viewBox="0 0 24 24"><path d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><table><thead><tr><th>Model</th><th>Type</th><th>Download</th></tr></thead><tbody><tr><td>30B</td><td>XOR</td><td><a href="https://huggingface.co/OpenAssistant/oasst-sft-6-llama-30b-xor" target="_blank" rel="noopener noreferrer">https://huggingface.co/OpenAssistant/oasst-sft-6-llama-30b-xor</a></td></tr><tr><td>30B GGML</td><td>CPU</td><td><a href="https://huggingface.co/MildlyAggressiveGoose1/ggml-oasst-sft-6-llama-30B-q4_2" target="_blank" rel="noopener noreferrer">Q4</a></td></tr><tr><td>30B</td><td>GPU</td><td><a href="https://huggingface.co/Peeepy/llama-33b-oasst-4bit" target="_blank" rel="noopener noreferrer">Q4 CUDA</a>, <a href="https://huggingface.co/Peeepy/llama-30b-oasst-4bit-128g" target="_blank" rel="noopener noreferrer">Q4 CUDA 128gs</a></td></tr></tbody></table><h2 class="anchor anchorWithStickyNavbar_KJCY" id="supercot-04222023">SuperCOT (04/22/2023)<a class="hash-link" href="#supercot-04222023" title="Direct link to heading">​</a></h2><p>!!! info</p><div class="codeBlockContainer_eErV theme-code-block" style="--prism-color:#bfc7d5;--prism-background-color:#292d3e"><div class="codeBlockContent_UzAP"><pre tabindex="0" class="prism-code language-text codeBlock_CYhB thin-scrollbar"><code class="codeBlockLines__AHC"><span class="token-line" style="color:#bfc7d5"><span class="token plain">SuperCOT is a LoRA trained with the aim of making LLaMa follow prompts for Langchain better, by infusing chain-of-thought datasets, code explanations and instructions, snippets, logical deductions and Alpaca GPT-4 prompts.</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">Though designed to improve Langchain, it&#x27;s quite versatile and works very well for other tasks like creative writing and chatbots. The author also pruned a number of filters from the datasets. As of early May 2023, it&#x27;s the most recommended model on /lmg/</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">&gt;Filtering : Light</span><br></span></code></pre><div class="buttonGroup_tnuT"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_tmcC" aria-hidden="true"><svg class="copyButtonIcon_Azkd" viewBox="0 0 24 24"><path d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg class="copyButtonSuccessIcon_pt5v" viewBox="0 0 24 24"><path d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><table><thead><tr><th>Model</th><th>Type</th><th>Download</th></tr></thead><tbody><tr><td>Original LoRA</td><td>LoRA</td><td><a href="https://huggingface.co/kaiokendev/SuperCOT-LoRA" target="_blank" rel="noopener noreferrer">https://huggingface.co/kaiokendev/SuperCOT-LoRA</a></td></tr><tr><td>13B GGML</td><td>CPU</td><td><a href="https://huggingface.co/camelids/llama-13b-supercot-ggml-q4_2" target="_blank" rel="noopener noreferrer">Q4</a>, <a href="https://huggingface.co/camelids/llama-13b-supercot-ggml-q8_0" target="_blank" rel="noopener noreferrer">Q8</a></td></tr><tr><td>30B GGML</td><td>CPU</td><td><a href="https://huggingface.co/camelids/llama-33b-supercot-ggml-q4_2" target="_blank" rel="noopener noreferrer">Q4</a>, <a href="https://huggingface.co/camelids/llama-33b-supercot-ggml-q5_1" target="_blank" rel="noopener noreferrer">Q5</a>, <a href="https://huggingface.co/camelids/llama-33b-supercot-ggml-q8_0" target="_blank" rel="noopener noreferrer">Q8</a></td></tr><tr><td>13B</td><td>GPU</td><td><a href="https://huggingface.co/ausboss/llama-13b-supercot-4bit-128g" target="_blank" rel="noopener noreferrer">Q4 CUDA 128gs</a></td></tr><tr><td>30B</td><td>GPU</td><td><a href="https://huggingface.co/tsumeone/llama-30b-supercot-4bit-cuda" target="_blank" rel="noopener noreferrer">Q4 CUDA</a>, <a href="https://huggingface.co/tsumeone/llama-30b-supercot-4bit-128g-cuda" target="_blank" rel="noopener noreferrer">Q4 CUDA 128gs</a></td></tr></tbody></table><h2 class="anchor anchorWithStickyNavbar_KJCY" id="previous-model-list">Previous Model List<a class="hash-link" href="#previous-model-list" title="Direct link to heading">​</a></h2><p>!!! info</p><div class="codeBlockContainer_eErV theme-code-block" style="--prism-color:#bfc7d5;--prism-background-color:#292d3e"><div class="codeBlockContent_UzAP"><pre tabindex="0" class="prism-code language-text codeBlock_CYhB thin-scrollbar"><code class="codeBlockLines__AHC"><span class="token-line" style="color:#bfc7d5"><span class="token plain">The old rentry, retained for archiving purposes. Contains older and outdated models.</span><br></span></code></pre><div class="buttonGroup_tnuT"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_tmcC" aria-hidden="true"><svg class="copyButtonIcon_Azkd" viewBox="0 0 24 24"><path d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg class="copyButtonSuccessIcon_pt5v" viewBox="0 0 24 24"><path d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p><a href="https://rentry.org/backupmdlist" target="_blank" rel="noopener noreferrer">https://rentry.org/backupmdlist</a></p><hr><h1>Models for <a href="https://github.com/ggerganov/llama.cpp" target="_blank" rel="noopener noreferrer">llama.cpp</a> (<a href="https://github.com/ggerganov/ggml" target="_blank" rel="noopener noreferrer">ggml</a> format)</h1><h2 class="anchor anchorWithStickyNavbar_KJCY" id="llama-quantized-4-bit-weights-ggml-q4_0">LLaMA quantized 4-bit weights (ggml q4_0)<a class="hash-link" href="#llama-quantized-4-bit-weights-ggml-q4_0" title="Direct link to heading">​</a></h2><h4 class="anchor anchorWithStickyNavbar_KJCY" id="2023-03-31-torrent-magnet"><a href="magnet:?xt=urn:btih:481dee5424b7024433504803a90efd32dae40fdf&amp;dn=LLaMA-ggml-4bit_2023-03-31&amp;tr=udp%3a%2f%2ftracker1.bt.moack.co.kr%3a80%2fannounce&amp;tr=udp%3a%2f%2ftracker.torrent.eu.org%3a451%2fannounce&amp;tr=udp%3a%2f%2ftracker.altrosky.nl%3a6969%2fannounce&amp;tr=udp%3a%2f%2fopentracker.i2p.rocks%3a6969%2fannounce&amp;tr=udp%3a%2f%2ftracker.opentrackr.org%3a1337%2fannounce&amp;tr=https%3a%2f%2fopentracker.i2p.rocks%3a443%2fannounce&amp;tr=udp%3a%2f%2ftracker.theoks.net%3a6969%2fannounce&amp;tr=udp%3a%2f%2ftracker-udp.gbitt.info%3a80%2fannounce&amp;tr=udp%3a%2f%2ftracker.tiny-vps.com%3a6969%2fannounce&amp;tr=udp%3a%2f%2ftracker.moeking.me%3a6969%2fannounce&amp;tr=udp%3a%2f%2f9.rarbg.com%3a2810%2fannounce&amp;tr=udp%3a%2f%2ftracker.openbittorrent.com%3a6969%2fannounce&amp;tr=udp%3a%2f%2ftracker.monitorit4.me%3a6969%2fannounce&amp;tr=udp%3a%2f%2ftracker.dler.org%3a6969%2fannounce&amp;tr=http%3a%2f%2ftracker.openbittorrent.com%3a80%2fannounce&amp;tr=udp%3a%2f%2ftracker2.dler.org%3a80%2fannounce" target="_blank" rel="noopener noreferrer">2023-03-31 torrent magnet</a><a class="hash-link" href="#2023-03-31-torrent-magnet" title="Direct link to heading">​</a></h4><p>!!! info <a href="https://github.com/ggerganov/llama.cpp#interactive-mode" target="_blank" rel="noopener noreferrer">Tutorial link for llama.cpp</a>
!!! info <a href="https://github.com/LostRuins/koboldcpp#usage" target="_blank" rel="noopener noreferrer">Tutorial link for koboldcpp</a></p><p>SHA256 checksums:</p><div class="language-text codeBlockContainer_eErV theme-code-block" style="--prism-color:#bfc7d5;--prism-background-color:#292d3e"><div class="codeBlockContent_UzAP"><pre tabindex="0" class="prism-code language-text codeBlock_CYhB thin-scrollbar"><code class="codeBlockLines__AHC"><span class="token-line" style="color:#bfc7d5"><span class="token plain">2dad53e70ca521fedcf9f9be5c26c15df602487a9c008bdafbb2bf8f946b6bf0  llama-7b-ggml-q4_0/ggml-model-q4_0.bin</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">9cd4d6c1f5f42d5abf529c51bde3303991fba912ab8ed452adfd7c97a4be77d7  llama-13b-ggml-q4_0/ggml-model-q4_0.bin</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">daefbc6b1b644a75be0286ef865253ab3786e96a2c1bca8b71216b1751eee63e  llama-33b-ggml-q4_0/ggml-model-q4_0.bin</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">d58a29c8403ecbd14258bbce07d90894fc5a8be25b9d359463c18f9f2ef96eb6  llama-65b-ggml-q4_0/ggml-model-q4_0.bin</span><br></span></code></pre><div class="buttonGroup_tnuT"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_tmcC" aria-hidden="true"><svg class="copyButtonIcon_Azkd" viewBox="0 0 24 24"><path d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg class="copyButtonSuccessIcon_pt5v" viewBox="0 0 24 24"><path d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p>ggml model file magic: <code>0x67676a74</code> (<code>ggjt</code> in hex)
ggml model file version: <code>1</code></p><h2 class="anchor anchorWithStickyNavbar_KJCY" id="alpaca-quantized-4-bit-weights-ggml-q4_0">Alpaca quantized 4-bit weights (ggml q4_0)<a class="hash-link" href="#alpaca-quantized-4-bit-weights-ggml-q4_0" title="Direct link to heading">​</a></h2><table><thead><tr><th>Model</th><th>Download</th></tr></thead><tbody><tr><td>LLaMA 7B fine-tune from <a href="https://huggingface.co/chavinlo/alpaca-native/tree/062111ff2af99db24f466562b8eb7e7e4ad7566d" target="_blank" rel="noopener noreferrer">chavinlo/alpaca-native</a></td><td><a href="magnet:?xt=urn:btih:d931a826b59443f4e543c18a25009b0ce8eabf39&amp;dn=Alpaca-7B-ggml-4bit-native-finetune_2023-03-31&amp;tr=udp%3a%2f%2ftracker.openbittorrent.com%3a6969%2fannounce&amp;tr=udp%3a%2f%2ftracker.altrosky.nl%3a6969%2fannounce&amp;tr=udp%3a%2f%2ftracker.dler.org%3a6969%2fannounce&amp;tr=udp%3a%2f%2ftracker1.bt.moack.co.kr%3a80%2fannounce&amp;tr=udp%3a%2f%2ftracker.moeking.me%3a6969%2fannounce&amp;tr=udp%3a%2f%2ftracker2.dler.org%3a80%2fannounce&amp;tr=udp%3a%2f%2ftracker.theoks.net%3a6969%2fannounce&amp;tr=udp%3a%2f%2ftracker.tiny-vps.com%3a6969%2fannounce&amp;tr=udp%3a%2f%2ftracker-udp.gbitt.info%3a80%2fannounce&amp;tr=udp%3a%2f%2fopentracker.i2p.rocks%3a6969%2fannounce&amp;tr=https%3a%2f%2fopentracker.i2p.rocks%3a443%2fannounce&amp;tr=http%3a%2f%2ftracker.openbittorrent.com%3a80%2fannounce&amp;tr=udp%3a%2f%2ftracker.torrent.eu.org%3a451%2fannounce&amp;tr=udp%3a%2f%2f9.rarbg.com%3a2810%2fannounce&amp;tr=udp%3a%2f%2ftracker.opentrackr.org%3a1337%2fannounce&amp;tr=udp%3a%2f%2ftracker.monitorit4.me%3a6969%2fannounce" target="_blank" rel="noopener noreferrer">2023-03-31 torrent magnet</a></td></tr><tr><td>LLaMA 7B merged with <a href="https://huggingface.co/tloen/alpaca-lora-7b/tree/28801eabf63a125cee9e46d8073fb13c7c8bd8b9" target="_blank" rel="noopener noreferrer">tloen/alpaca-lora-7b</a> LoRA</td><td><a href="magnet:?xt=urn:btih:694e206c1ce2780db673bdc2ecee78abcf228324&amp;dn=Alpaca-7B-ggml-4bit-LoRA-merged_2023-03-31&amp;tr=udp%3a%2f%2ftracker1.bt.moack.co.kr%3a80%2fannounce&amp;tr=udp%3a%2f%2ftracker.monitorit4.me%3a6969%2fannounce&amp;tr=udp%3a%2f%2ftracker.openbittorrent.com%3a6969%2fannounce&amp;tr=udp%3a%2f%2ftracker.dler.org%3a6969%2fannounce&amp;tr=http%3a%2f%2ftracker.openbittorrent.com%3a80%2fannounce&amp;tr=udp%3a%2f%2ftracker.moeking.me%3a6969%2fannounce&amp;tr=udp%3a%2f%2ftracker-udp.gbitt.info%3a80%2fannounce&amp;tr=udp%3a%2f%2ftracker.theoks.net%3a6969%2fannounce&amp;tr=udp%3a%2f%2fopentracker.i2p.rocks%3a6969%2fannounce&amp;tr=udp%3a%2f%2ftracker.opentrackr.org%3a1337%2fannounce&amp;tr=https%3a%2f%2fopentracker.i2p.rocks%3a443%2fannounce&amp;tr=udp%3a%2f%2ftracker.altrosky.nl%3a6969%2fannounce&amp;tr=udp%3a%2f%2ftracker.tiny-vps.com%3a6969%2fannounce&amp;tr=udp%3a%2f%2ftracker2.dler.org%3a80%2fannounce&amp;tr=udp%3a%2f%2ftracker.torrent.eu.org%3a451%2fannounce&amp;tr=udp%3a%2f%2f9.rarbg.com%3a2810%2fannounce" target="_blank" rel="noopener noreferrer">2023-03-31 torrent magnet</a></td></tr><tr><td>LLaMA 13B merged with <a href="https://huggingface.co/chansung/alpaca-lora-13b/tree/abcdddb2778cace16f184dc1dda0ecf21ade23bc" target="_blank" rel="noopener noreferrer">chansung/alpaca-lora-13b</a> LoRA</td><td><a href="magnet:?xt=urn:btih:31ad0f8e8da5d43bad83eeed94f24cca504330d1&amp;dn=Alpaca-13B-ggml-4bit-LoRA-merged_2023-03-31&amp;tr=udp%3a%2f%2ftracker.openbittorrent.com%3a6969%2fannounce&amp;tr=http%3a%2f%2ftracker.openbittorrent.com%3a80%2fannounce&amp;tr=udp%3a%2f%2f9.rarbg.com%3a2810%2fannounce&amp;tr=udp%3a%2f%2fopentracker.i2p.rocks%3a6969%2fannounce&amp;tr=udp%3a%2f%2ftracker.monitorit4.me%3a6969%2fannounce&amp;tr=https%3a%2f%2fopentracker.i2p.rocks%3a443%2fannounce&amp;tr=udp%3a%2f%2ftracker.moeking.me%3a6969%2fannounce&amp;tr=udp%3a%2f%2ftracker1.bt.moack.co.kr%3a80%2fannounce&amp;tr=udp%3a%2f%2ftracker.opentrackr.org%3a1337%2fannounce&amp;tr=udp%3a%2f%2ftracker.altrosky.nl%3a6969%2fannounce&amp;tr=udp%3a%2f%2ftracker2.dler.org%3a80%2fannounce&amp;tr=udp%3a%2f%2ftracker.theoks.net%3a6969%2fannounce&amp;tr=udp%3a%2f%2ftracker-udp.gbitt.info%3a80%2fannounce&amp;tr=udp%3a%2f%2ftracker.dler.org%3a6969%2fannounce&amp;tr=udp%3a%2f%2ftracker.torrent.eu.org%3a451%2fannounce&amp;tr=udp%3a%2f%2ftracker.tiny-vps.com%3a6969%2fannounce" target="_blank" rel="noopener noreferrer">2023-03-31 torrent magnet</a></td></tr><tr><td>LLaMA 33B merged with <a href="https://huggingface.co/chansung/alpaca-lora-30b/tree/bbbc77a38ad00a64780a76d119c783b6dc8200bd" target="_blank" rel="noopener noreferrer">chansung/alpaca-lora-30b</a> LoRA</td><td><a href="magnet:?xt=urn:btih:1e8681e255ec3078ef84fe4cdecdc7abd8b2b6e5&amp;dn=Alpaca-33B-ggml-4bit-LoRA-merged_2023-03-31&amp;tr=udp%3a%2f%2ftracker-udp.gbitt.info%3a80%2fannounce&amp;tr=udp%3a%2f%2f9.rarbg.com%3a2810%2fannounce&amp;tr=udp%3a%2f%2ftracker.moeking.me%3a6969%2fannounce&amp;tr=udp%3a%2f%2ftracker.tiny-vps.com%3a6969%2fannounce&amp;tr=udp%3a%2f%2ftracker.dler.org%3a6969%2fannounce&amp;tr=udp%3a%2f%2ftracker.monitorit4.me%3a6969%2fannounce&amp;tr=udp%3a%2f%2ftracker.theoks.net%3a6969%2fannounce&amp;tr=udp%3a%2f%2ftracker.opentrackr.org%3a1337%2fannounce&amp;tr=udp%3a%2f%2ftracker2.dler.org%3a80%2fannounce&amp;tr=udp%3a%2f%2ftracker.openbittorrent.com%3a6969%2fannounce&amp;tr=http%3a%2f%2ftracker.openbittorrent.com%3a80%2fannounce&amp;tr=udp%3a%2f%2fopentracker.i2p.rocks%3a6969%2fannounce&amp;tr=https%3a%2f%2fopentracker.i2p.rocks%3a443%2fannounce&amp;tr=udp%3a%2f%2ftracker.torrent.eu.org%3a451%2fannounce&amp;tr=udp%3a%2f%2ftracker1.bt.moack.co.kr%3a80%2fannounce&amp;tr=udp%3a%2f%2ftracker.altrosky.nl%3a6969%2fannounce" target="_blank" rel="noopener noreferrer">2023-03-31 torrent magnet</a></td></tr></tbody></table><p>!!! info <a href="https://github.com/ggerganov/llama.cpp#instruction-mode-with-alpaca" target="_blank" rel="noopener noreferrer">Tutorial link for llama.cpp</a>
Example:
<code>./main --model ggml-model-q4_0.bin --file prompts/alpaca.txt --instruct --ctx_size 2048 --keep -1</code>
!!! info <a href="https://github.com/LostRuins/koboldcpp#usage" target="_blank" rel="noopener noreferrer">Tutorial link for koboldcpp</a></p><p>SHA256 checksums:</p><div class="language-text codeBlockContainer_eErV theme-code-block" style="--prism-color:#bfc7d5;--prism-background-color:#292d3e"><div class="codeBlockContent_UzAP"><pre tabindex="0" class="prism-code language-text codeBlock_CYhB thin-scrollbar"><code class="codeBlockLines__AHC"><span class="token-line" style="color:#bfc7d5"><span class="token plain">f5e264b10944c55a84810e8073dfdcd653fa8e47ff50ea043ec071051ac7821d  alpaca-7b-ggml-q4_0-native-finetune/ggml-model-q4_0.bin</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">d9777baad5cf6a5d196e70867338d8cc3c7af68c7744e68de839a522983860d7  alpaca-7b-ggml-q4_0-lora-merged/ggml-model-q4_0.bin</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">3838aa32651c65948e289374abd71f6feab1a62a4921a648e30d979df86a4af3  alpaca-13b-ggml-q4_0-lora-merged/ggml-model-q4_0.bin</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">2267ed1dc0bf0d6d300ba292c25083c7fa5395f3726c7c68a49b2be19a64b349  alpaca-33b-ggml-q4_0-lora-merged/ggml-model-q4_0.bin</span><br></span></code></pre><div class="buttonGroup_tnuT"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_tmcC" aria-hidden="true"><svg class="copyButtonIcon_Azkd" viewBox="0 0 24 24"><path d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg class="copyButtonSuccessIcon_pt5v" viewBox="0 0 24 24"><path d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p>ggml model file magic: <code>0x67676a74</code> (<code>ggjt</code> in hex)
ggml model file version: <code>1</code></p><h2 class="anchor anchorWithStickyNavbar_KJCY" id="gpt4all-7b-quantized-4-bit-weights-ggml-q4_0">GPT4All 7B quantized 4-bit weights (ggml q4_0)<a class="hash-link" href="#gpt4all-7b-quantized-4-bit-weights-ggml-q4_0" title="Direct link to heading">​</a></h2><h4 class="anchor anchorWithStickyNavbar_KJCY" id="2023-03-31-torrent-magnet-1"><a href="magnet:?xt=urn:btih:04584d8e5799c7838ccb987fae4f183936b9d744&amp;dn=GPT4All-7B-ggml-4bit-lora-merged_2023-03-31&amp;tr=udp%3a%2f%2ftracker1.bt.moack.co.kr%3a80%2fannounce&amp;tr=udp%3a%2f%2ftracker.monitorit4.me%3a6969%2fannounce&amp;tr=udp%3a%2f%2ftracker.theoks.net%3a6969%2fannounce&amp;tr=udp%3a%2f%2f9.rarbg.com%3a2810%2fannounce&amp;tr=udp%3a%2f%2ftracker.opentrackr.org%3a1337%2fannounce&amp;tr=udp%3a%2f%2ftracker.openbittorrent.com%3a6969%2fannounce&amp;tr=http%3a%2f%2ftracker.openbittorrent.com%3a80%2fannounce&amp;tr=udp%3a%2f%2ftracker.tiny-vps.com%3a6969%2fannounce&amp;tr=udp%3a%2f%2ftracker.altrosky.nl%3a6969%2fannounce&amp;tr=udp%3a%2f%2ftracker.dler.org%3a6969%2fannounce&amp;tr=udp%3a%2f%2ftracker2.dler.org%3a80%2fannounce&amp;tr=udp%3a%2f%2ftracker.moeking.me%3a6969%2fannounce&amp;tr=udp%3a%2f%2ftracker-udp.gbitt.info%3a80%2fannounce&amp;tr=udp%3a%2f%2fopentracker.i2p.rocks%3a6969%2fannounce&amp;tr=https%3a%2f%2fopentracker.i2p.rocks%3a443%2fannounce&amp;tr=udp%3a%2f%2ftracker.torrent.eu.org%3a451%2fannounce" target="_blank" rel="noopener noreferrer">2023-03-31 torrent magnet</a><a class="hash-link" href="#2023-03-31-torrent-magnet-1" title="Direct link to heading">​</a></h4><p>!!! info <a href="https://github.com/ggerganov/llama.cpp#interactive-mode" target="_blank" rel="noopener noreferrer">Tutorial link for llama.cpp</a>
GPT4All can be used with llama.cpp in the same way as the other <code>ggml</code> models.
!!! info <a href="https://github.com/LostRuins/koboldcpp#usage" target="_blank" rel="noopener noreferrer">Tutorial link for koboldcpp</a></p><p>SHA256 checksums:</p><div class="language-text codeBlockContainer_eErV theme-code-block" style="--prism-color:#bfc7d5;--prism-background-color:#292d3e"><div class="codeBlockContent_UzAP"><pre tabindex="0" class="prism-code language-text codeBlock_CYhB thin-scrollbar"><code class="codeBlockLines__AHC"><span class="token-line" style="color:#bfc7d5"><span class="token plain">9f6cd4830a3c45a86147c80a32888e7be8f8a489284c87cdb882a7cfe40940c1  gpt4all-unfiltered-7b-ggml-q4_0-lora-merged/ggml-model-q4_0.bin</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">de314c5ee155ac40a03ca3b3be85ba2b02aef9e9f083c411c0b4490689dd047e  gpt4all-7b-ggml-q4_0-lora-merged/ggml-model-q4_0.bin</span><br></span></code></pre><div class="buttonGroup_tnuT"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_tmcC" aria-hidden="true"><svg class="copyButtonIcon_Azkd" viewBox="0 0 24 24"><path d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg class="copyButtonSuccessIcon_pt5v" viewBox="0 0 24 24"><path d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p>ggml model file magic: <code>0x67676a74</code> (<code>ggjt</code> in hex)
ggml model file version: <code>1</code></p><h2 class="anchor anchorWithStickyNavbar_KJCY" id="gpt4-x-alpaca-13b-quantized-4-bit-weights-ggml-q4_0">GPT4 x Alpaca 13B quantized 4-bit weights (ggml q4_0)<a class="hash-link" href="#gpt4-x-alpaca-13b-quantized-4-bit-weights-ggml-q4_0" title="Direct link to heading">​</a></h2><h4 class="anchor anchorWithStickyNavbar_KJCY" id="2023-04-01-torrent-magnet"><a href="magnet:?xt=urn:btih:f77827abd0cfb77399a0b281a1dbaeac5c386413&amp;dn=GPT4-x-Alpaca-13B-ggml-4bit_2023-04-01&amp;tr=udp%3a%2f%2ftracker.altrosky.nl%3a6969%2fannounce&amp;tr=udp%3a%2f%2ftracker-udp.gbitt.info%3a80%2fannounce&amp;tr=udp%3a%2f%2ftracker.theoks.net%3a6969%2fannounce&amp;tr=udp%3a%2f%2ftracker.moeking.me%3a6969%2fannounce&amp;tr=udp%3a%2f%2ftracker1.bt.moack.co.kr%3a80%2fannounce&amp;tr=udp%3a%2f%2ftracker.openbittorrent.com%3a6969%2fannounce&amp;tr=udp%3a%2f%2fopentracker.i2p.rocks%3a6969%2fannounce&amp;tr=udp%3a%2f%2ftracker.torrent.eu.org%3a451%2fannounce&amp;tr=https%3a%2f%2fopentracker.i2p.rocks%3a443%2fannounce&amp;tr=udp%3a%2f%2ftracker2.dler.org%3a80%2fannounce&amp;tr=udp%3a%2f%2ftracker.dler.org%3a6969%2fannounce&amp;tr=http%3a%2f%2ftracker.openbittorrent.com%3a80%2fannounce&amp;tr=udp%3a%2f%2ftracker.tiny-vps.com%3a6969%2fannounce&amp;tr=udp%3a%2f%2f9.rarbg.com%3a2810%2fannounce&amp;tr=udp%3a%2f%2ftracker.monitorit4.me%3a6969%2fannounce&amp;tr=udp%3a%2f%2ftracker.opentrackr.org%3a1337%2fannounce" target="_blank" rel="noopener noreferrer">2023-04-01 torrent magnet</a><a class="hash-link" href="#2023-04-01-torrent-magnet" title="Direct link to heading">​</a></h4><p>!!! info <a href="https://github.com/ggerganov/llama.cpp#interactive-mode" target="_blank" rel="noopener noreferrer">Tutorial link for llama.cpp</a>
GPT4 x Alpaca can be used with llama.cpp in the same way as the other <code>ggml</code> models.
Text generation with this version is faster compared to the <a href="https://rentry.org/nur779#gpt4-x-alpaca-13b-quantized-4-bit-weights-ggml-q4_1-from-gptq-with-groupsize-128" target="_blank" rel="noopener noreferrer">GPTQ-quantized one</a>.
!!! info <a href="https://github.com/LostRuins/koboldcpp#usage" target="_blank" rel="noopener noreferrer">Tutorial link for koboldcpp</a></p><p>SHA256 checksum:</p><div class="language-text codeBlockContainer_eErV theme-code-block" style="--prism-color:#bfc7d5;--prism-background-color:#292d3e"><div class="codeBlockContent_UzAP"><pre tabindex="0" class="prism-code language-text codeBlock_CYhB thin-scrollbar"><code class="codeBlockLines__AHC"><span class="token-line" style="color:#bfc7d5"><span class="token plain">e6b77ebf297946949b25b3c4b870f10cdc98fb9fcaa6d19cef4dda9021031580  gpt4-x-alpaca-13b-ggml-q4_0/ggml-model-q4_0.bin</span><br></span></code></pre><div class="buttonGroup_tnuT"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_tmcC" aria-hidden="true"><svg class="copyButtonIcon_Azkd" viewBox="0 0 24 24"><path d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg class="copyButtonSuccessIcon_pt5v" viewBox="0 0 24 24"><path d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p>ggml model file magic: <code>0x67676a74</code> (<code>ggjt</code> in hex)
ggml model file version: <code>1</code></p><p><a href="https://desuarchive.org/g/thread/92479457/#q92481589" target="_blank" rel="noopener noreferrer">Model source</a></p><h2 class="anchor anchorWithStickyNavbar_KJCY" id="gpt4-x-alpaca-13b-quantized-4-bit-weights-ggml-q4_1-from-gptq-with-groupsize-128">GPT4 x Alpaca 13B quantized 4-bit weights (ggml q4_1 from GPTQ with groupsize 128)<a class="hash-link" href="#gpt4-x-alpaca-13b-quantized-4-bit-weights-ggml-q4_1-from-gptq-with-groupsize-128" title="Direct link to heading">​</a></h2><h4 class="anchor anchorWithStickyNavbar_KJCY" id="2023-04-01-torrent-magnet-1"><a href="magnet:?xt=urn:btih:6cdb6ab819b13b00928182eea72106824e335734&amp;dn=GPT4-x-Alpaca-13B-ggml-4bit-from-GPTQ-128g_2023-04-01&amp;tr=udp%3a%2f%2ftracker-udp.gbitt.info%3a80%2fannounce&amp;tr=udp%3a%2f%2ftracker.torrent.eu.org%3a451%2fannounce&amp;tr=udp%3a%2f%2ftracker.dler.org%3a6969%2fannounce&amp;tr=udp%3a%2f%2ftracker.moeking.me%3a6969%2fannounce&amp;tr=udp%3a%2f%2ftracker.tiny-vps.com%3a6969%2fannounce&amp;tr=udp%3a%2f%2ftracker.openbittorrent.com%3a6969%2fannounce&amp;tr=udp%3a%2f%2fopentracker.i2p.rocks%3a6969%2fannounce&amp;tr=udp%3a%2f%2ftracker.altrosky.nl%3a6969%2fannounce&amp;tr=udp%3a%2f%2ftracker.theoks.net%3a6969%2fannounce&amp;tr=https%3a%2f%2fopentracker.i2p.rocks%3a443%2fannounce&amp;tr=udp%3a%2f%2ftracker.opentrackr.org%3a1337%2fannounce&amp;tr=udp%3a%2f%2f9.rarbg.com%3a2810%2fannounce&amp;tr=udp%3a%2f%2ftracker1.bt.moack.co.kr%3a80%2fannounce&amp;tr=udp%3a%2f%2ftracker.monitorit4.me%3a6969%2fannounce&amp;tr=udp%3a%2f%2ftracker2.dler.org%3a80%2fannounce&amp;tr=http%3a%2f%2ftracker.openbittorrent.com%3a80%2fannounce" target="_blank" rel="noopener noreferrer">2023-04-01 torrent magnet</a><a class="hash-link" href="#2023-04-01-torrent-magnet-1" title="Direct link to heading">​</a></h4><p>!!! info <a href="https://github.com/ggerganov/llama.cpp#interactive-mode" target="_blank" rel="noopener noreferrer">Tutorial link for llama.cpp</a>
GPT4 x Alpaca can be used with llama.cpp in the same way as the other <code>ggml</code> models.
!!! info <a href="https://github.com/LostRuins/koboldcpp#usage" target="_blank" rel="noopener noreferrer">Tutorial link for koboldcpp</a></p><p>SHA256 checksum:</p><div class="language-text codeBlockContainer_eErV theme-code-block" style="--prism-color:#bfc7d5;--prism-background-color:#292d3e"><div class="codeBlockContent_UzAP"><pre tabindex="0" class="prism-code language-text codeBlock_CYhB thin-scrollbar"><code class="codeBlockLines__AHC"><span class="token-line" style="color:#bfc7d5"><span class="token plain">d4a640a1ce33009c244a361c6f87733aacbc2bea90e84d3c304a4c8be2bdf22d  gpt4-x-alpaca-13b-ggml-q4_1-from-gptq-4bit-128g/ggml-model-q4_1.bin</span><br></span></code></pre><div class="buttonGroup_tnuT"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_tmcC" aria-hidden="true"><svg class="copyButtonIcon_Azkd" viewBox="0 0 24 24"><path d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg class="copyButtonSuccessIcon_pt5v" viewBox="0 0 24 24"><path d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p>ggml model file magic: <code>0x67676a74</code> (<code>ggjt</code> in hex)
ggml model file version: <code>1</code></p><p><a href="https://desuarchive.org/g/thread/92479457/#q92481589" target="_blank" rel="noopener noreferrer">Model source</a></p><h2 class="anchor anchorWithStickyNavbar_KJCY" id="vicuna-13b-quantized-4-bit-weights-ggml-q4_0">Vicuna 13B quantized 4-bit weights (ggml q4_0)<a class="hash-link" href="#vicuna-13b-quantized-4-bit-weights-ggml-q4_0" title="Direct link to heading">​</a></h2><h4 class="anchor anchorWithStickyNavbar_KJCY" id="2023-04-03-torrent-magnet"><a href="magnet:?xt=urn:btih:1e0c3dbeefe82483f81bd4e7ea959e4953c8081f&amp;dn=Vicuna-13B-ggml-4bit-delta-merged_2023-04-03&amp;tr=udp%3a%2f%2ftracker.opentrackr.org%3a1337%2fannounce&amp;tr=udp%3a%2f%2f9.rarbg.com%3a2810%2fannounce&amp;tr=udp%3a%2f%2ftracker.monitorit4.me%3a6969%2fannounce&amp;tr=udp%3a%2f%2ftracker2.dler.org%3a80%2fannounce&amp;tr=udp%3a%2f%2fopentracker.i2p.rocks%3a6969%2fannounce&amp;tr=udp%3a%2f%2ftracker.torrent.eu.org%3a451%2fannounce&amp;tr=udp%3a%2f%2ftracker.openbittorrent.com%3a6969%2fannounce&amp;tr=udp%3a%2f%2ftracker.dler.org%3a6969%2fannounce&amp;tr=udp%3a%2f%2ftracker-udp.gbitt.info%3a80%2fannounce&amp;tr=udp%3a%2f%2ftracker1.bt.moack.co.kr%3a80%2fannounce&amp;tr=https%3a%2f%2fopentracker.i2p.rocks%3a443%2fannounce&amp;tr=udp%3a%2f%2ftracker.altrosky.nl%3a6969%2fannounce&amp;tr=udp%3a%2f%2ftracker.tiny-vps.com%3a6969%2fannounce&amp;tr=udp%3a%2f%2ftracker.moeking.me%3a6969%2fannounce&amp;tr=http%3a%2f%2ftracker.openbittorrent.com%3a80%2fannounce&amp;tr=udp%3a%2f%2ftracker.theoks.net%3a6969%2fannounce" target="_blank" rel="noopener noreferrer">2023-04-03 torrent magnet</a><a class="hash-link" href="#2023-04-03-torrent-magnet" title="Direct link to heading">​</a></h4><p>!!! info <a href="https://github.com/ggerganov/llama.cpp#interactive-mode" target="_blank" rel="noopener noreferrer">Tutorial link for llama.cpp</a>
Vicuna can be used with llama.cpp in the same way as the other <code>ggml</code> models.
!!! info <a href="https://github.com/LostRuins/koboldcpp#usage" target="_blank" rel="noopener noreferrer">Tutorial link for koboldcpp</a></p><p>SHA256 checksum:</p><div class="language-text codeBlockContainer_eErV theme-code-block" style="--prism-color:#bfc7d5;--prism-background-color:#292d3e"><div class="codeBlockContent_UzAP"><pre tabindex="0" class="prism-code language-text codeBlock_CYhB thin-scrollbar"><code class="codeBlockLines__AHC"><span class="token-line" style="color:#bfc7d5"><span class="token plain">f96689a13c581f53b616887b2efe82bbfbc5321258dbcfdbe69a22076a7da461  vicuna-13b-ggml-q4_0-delta-merged/ggml-model-q4_0.bin</span><br></span></code></pre><div class="buttonGroup_tnuT"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_tmcC" aria-hidden="true"><svg class="copyButtonIcon_Azkd" viewBox="0 0 24 24"><path d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg class="copyButtonSuccessIcon_pt5v" viewBox="0 0 24 24"><path d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p>ggml model file magic: <code>0x67676a74</code> (<code>ggjt</code> in hex)
ggml model file version: <code>1</code></p><p><a href="https://huggingface.co/lmsys/vicuna-13b-delta/tree/da39ef5c586459f4d509bf7382475af584277e71" target="_blank" rel="noopener noreferrer">Model source</a></p><h2 class="anchor anchorWithStickyNavbar_KJCY" id="openassistant-llama-13b-quantized-4-bit-weights-ggml-q4_0--q4_1">OpenAssistant LLaMA 13B quantized 4-bit weights (ggml q4_0 &amp; q4_1)<a class="hash-link" href="#openassistant-llama-13b-quantized-4-bit-weights-ggml-q4_0--q4_1" title="Direct link to heading">​</a></h2><p>!!! warning Note that this model is <a href="https://huggingface.co/dvruette/oasst-llama-13b-2-epochs/discussions/1#642ec79032e711e21aa11b60" target="_blank" rel="noopener noreferrer">work-in-progress</a>.</p><h4 class="anchor anchorWithStickyNavbar_KJCY" id="2023-04-07-torrent-magnet--huggingface-hub-direct-download"><a href="magnet:?xt=urn:btih:cad2f029978033f9c1487df3965546cc4d44489a&amp;xt=urn:btmh:1220140702f43fbf90157db9531ad0454020bc212fddc48c7c30f593ec40d26eb19b&amp;dn=oasst-llama-13b-ggml&amp;tr=udp%3a%2f%2ftracker.opentrackr.org%3a1337%2fannounce&amp;tr=udp%3a%2f%2f9.rarbg.com%3a2810%2fannounce&amp;tr=udp%3a%2f%2ftracker.monitorit4.me%3a6969%2fannounce&amp;tr=udp%3a%2f%2ftracker2.dler.org%3a80%2fannounce&amp;tr=udp%3a%2f%2fopentracker.i2p.rocks%3a6969%2fannounce&amp;tr=udp%3a%2f%2ftracker.torrent.eu.org%3a451%2fannounce&amp;tr=udp%3a%2f%2ftracker.openbittorrent.com%3a6969%2fannounce&amp;tr=udp%3a%2f%2ftracker.dler.org%3a6969%2fannounce&amp;tr=udp%3a%2f%2ftracker-udp.gbitt.info%3a80%2fannounce&amp;tr=udp%3a%2f%2ftracker1.bt.moack.co.kr%3a80%2fannounce&amp;tr=https%3a%2f%2fopentracker.i2p.rocks%3a443%2fannounce&amp;tr=udp%3a%2f%2ftracker.altrosky.nl%3a6969%2fannounce&amp;tr=udp%3a%2f%2ftracker.tiny-vps.com%3a6969%2fannounce&amp;tr=udp%3a%2f%2ftracker.moeking.me%3a6969%2fannounce&amp;tr=http%3a%2f%2ftracker.openbittorrent.com%3a80%2fannounce&amp;tr=udp%3a%2f%2ftracker.theoks.net%3a6969%2fannounce" target="_blank" rel="noopener noreferrer">2023-04-07 torrent magnet</a> | <a href="https://huggingface.co/Black-Engineer/oasst-llama13b-ggml-q4/tree/main" target="_blank" rel="noopener noreferrer">HuggingFace Hub direct download</a><a class="hash-link" href="#2023-04-07-torrent-magnet--huggingface-hub-direct-download" title="Direct link to heading">​</a></h4><p>!!! info <a href="https://github.com/ggerganov/llama.cpp#interactive-mode" target="_blank" rel="noopener noreferrer">Tutorial link for llama.cpp</a>
!!! info <a href="https://github.com/LostRuins/koboldcpp#usage" target="_blank" rel="noopener noreferrer">Tutorial link for koboldcpp</a></p><p>SHA256 checksums:</p><div class="language-text codeBlockContainer_eErV theme-code-block" style="--prism-color:#bfc7d5;--prism-background-color:#292d3e"><div class="codeBlockContent_UzAP"><pre tabindex="0" class="prism-code language-text codeBlock_CYhB thin-scrollbar"><code class="codeBlockLines__AHC"><span class="token-line" style="color:#bfc7d5"><span class="token plain">fe77206c7890ecd0824c7b6b6a6deab92e471366b2e4271c05ece9a686474ef6  ggml-model-q4_0.bin</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">412da683b6ab0f710ce0adc8bc36db52bb92df96698558c5f2a1399af9bd0a78  ggml-model-q4_1.bin</span><br></span></code></pre><div class="buttonGroup_tnuT"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_tmcC" aria-hidden="true"><svg class="copyButtonIcon_Azkd" viewBox="0 0 24 24"><path d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg class="copyButtonSuccessIcon_pt5v" viewBox="0 0 24 24"><path d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p>ggml model file magic: <code>0x67676a74</code> (<code>ggjt</code> in hex)
ggml model file version: <code>1</code></p><p><a href="https://huggingface.co/dvruette/oasst-llama-13b-2-epochs" target="_blank" rel="noopener noreferrer">Original model source</a>
<a href="https://huggingface.co/gozfarb/oasst-llama13b-4bit-128g" target="_blank" rel="noopener noreferrer">GPTQ-quantized model source</a>
<a href="https://desuarchive.org/g/thread/92596368/#q92601864" target="_blank" rel="noopener noreferrer">Torrent source</a></p><hr><h1>Models for HuggingFace 🤗</h1><p>!!! danger Updated tokenizer and model configuration files can be found <a href="https://rentry.org/544p2" target="_blank" rel="noopener noreferrer">here</a>.
Ensure that your models have the appropriate JSON files within the same directory as the weights, otherwise text generation might be impacted by tokenization problems. The issues were addressed <a href="https://github.com/huggingface/transformers/pull/22402" target="_blank" rel="noopener noreferrer">here</a> and <a href="https://github.com/lm-sys/FastChat/pull/167" target="_blank" rel="noopener noreferrer">here</a>, but a manual update of both the <code>transformers</code> library and your model configuration files is required.</p><h2 class="anchor anchorWithStickyNavbar_KJCY" id="llama-float16-weights">LLaMA float16 weights<a class="hash-link" href="#llama-float16-weights" title="Direct link to heading">​</a></h2><h4 class="anchor anchorWithStickyNavbar_KJCY" id="2023-03-26-torrent-magnet--huggingface-hub-direct-downloads"><a href="magnet:?xt=urn:btih:496ee41a35f8d845f6d6cba11baa8b332f3c3318&amp;dn=Safe-LLaMA-HF%20(3-26-23)&amp;tr=http%3a%2f%2fbt2.archive.org%3a6969%2fannounce&amp;tr=http%3a%2f%2fbt1.archive.org%3a6969%2fannounce" target="_blank" rel="noopener noreferrer">2023-03-26 torrent magnet</a> | <a href="https://huggingface.co/Neko-Institute-of-Science" target="_blank" rel="noopener noreferrer">HuggingFace Hub direct downloads</a><a class="hash-link" href="#2023-03-26-torrent-magnet--huggingface-hub-direct-downloads" title="Direct link to heading">​</a></h4><p>!!! info <a href="https://github.com/oobabooga/text-generation-webui/wiki/LLaMA-model#hugging-face-format-weights" target="_blank" rel="noopener noreferrer">Tutorial link for Text generation web UI</a></p><p><a href="https://github.com/oobabooga/text-generation-webui/pull/530#issuecomment-1484235789" target="_blank" rel="noopener noreferrer">Torrent source and SHA256 checksums</a></p><h2 class="anchor anchorWithStickyNavbar_KJCY" id="vicuna-13b-float16-weights">Vicuna 13B float16 weights<a class="hash-link" href="#vicuna-13b-float16-weights" title="Direct link to heading">​</a></h2><h4 class="anchor anchorWithStickyNavbar_KJCY" id="2023-04-03-torrent-magnet-1"><a href="magnet:?xt=urn:btih:a7fac57094561a63d53eed943f904abf24c6969d&amp;dn=Vicuna-13B-HF-fp16-delta-merged_2023-04-03&amp;tr=udp%3a%2f%2ftracker.opentrackr.org%3a1337%2fannounce&amp;tr=udp%3a%2f%2ftracker-udp.gbitt.info%3a80%2fannounce&amp;tr=udp%3a%2f%2ftracker1.bt.moack.co.kr%3a80%2fannounce&amp;tr=udp%3a%2f%2ftracker.tiny-vps.com%3a6969%2fannounce&amp;tr=udp%3a%2f%2ftracker2.dler.org%3a80%2fannounce&amp;tr=udp%3a%2f%2fopentracker.i2p.rocks%3a6969%2fannounce&amp;tr=udp%3a%2f%2ftracker.altrosky.nl%3a6969%2fannounce&amp;tr=udp%3a%2f%2ftracker.theoks.net%3a6969%2fannounce&amp;tr=udp%3a%2f%2ftracker.dler.org%3a6969%2fannounce&amp;tr=udp%3a%2f%2ftracker.torrent.eu.org%3a451%2fannounce&amp;tr=udp%3a%2f%2ftracker.openbittorrent.com%3a6969%2fannounce&amp;tr=https%3a%2f%2fopentracker.i2p.rocks%3a443%2fannounce&amp;tr=http%3a%2f%2ftracker.openbittorrent.com%3a80%2fannounce&amp;tr=udp%3a%2f%2ftracker.moeking.me%3a6969%2fannounce&amp;tr=udp%3a%2f%2ftracker.monitorit4.me%3a6969%2fannounce&amp;tr=udp%3a%2f%2f9.rarbg.com%3a2810%2fannounce" target="_blank" rel="noopener noreferrer">2023-04-03 torrent magnet</a><a class="hash-link" href="#2023-04-03-torrent-magnet-1" title="Direct link to heading">​</a></h4><p>!!! info <a href="https://github.com/oobabooga/text-generation-webui/wiki/LLaMA-model#hugging-face-format-weights" target="_blank" rel="noopener noreferrer">Tutorial link for Text generation web UI</a></p><p><a href="https://huggingface.co/lmsys/vicuna-13b-delta/tree/da39ef5c586459f4d509bf7382475af584277e71" target="_blank" rel="noopener noreferrer">Model source</a></p><h2 class="anchor anchorWithStickyNavbar_KJCY" id="llama-quantized-4-bit-weights-gptq-format-without-groupsize">LLaMA quantized 4-bit weights (<a href="https://github.com/qwopqwop200/GPTQ-for-LLaMa" target="_blank" rel="noopener noreferrer">GPTQ</a> format without groupsize)<a class="hash-link" href="#llama-quantized-4-bit-weights-gptq-format-without-groupsize" title="Direct link to heading">​</a></h2><h4 class="anchor anchorWithStickyNavbar_KJCY" id="2023-03-26-torrent-magnet"><a href="magnet:?xt=urn:btih:e88abf1b84290b162f00d3a9d79fb4f8719c2053&amp;dn=LLaMA-HF-4bit&amp;tr=http%3a%2f%2fbt2.archive.org%3a6969%2fannounce&amp;tr=http%3a%2f%2fbt1.archive.org%3a6969%2fannounce" target="_blank" rel="noopener noreferrer">2023-03-26 torrent magnet</a><a class="hash-link" href="#2023-03-26-torrent-magnet" title="Direct link to heading">​</a></h4><p>!!! info <a href="https://github.com/oobabooga/text-generation-webui/wiki/LLaMA-model#4-bit-mode" target="_blank" rel="noopener noreferrer">Tutorial link for Text generation web UI</a></p><p>SHA256 checksums:</p><div class="language-text codeBlockContainer_eErV theme-code-block" style="--prism-color:#bfc7d5;--prism-background-color:#292d3e"><div class="codeBlockContent_UzAP"><pre tabindex="0" class="prism-code language-text codeBlock_CYhB thin-scrollbar"><code class="codeBlockLines__AHC"><span class="token-line" style="color:#bfc7d5"><span class="token plain">09841a1c4895e1da3b05c1bdbfb8271c6d43812661e4348c862ff2ab1e6ff5b3  llama-7b-4bit/llama-7b-4bit.safetensors</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">edfa0b4060aae392b1e9df21fb60a97d78c9268ac6972e3888f6dc955ba0377b  llama-13b-4bit/llama-13b-4bit.safetensors</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">4cb560746fe58796233159612d8d3c9dbdebdf6f0443b47be71643f2f91b8541  llama-30b-4bit/llama-30b-4bit.safetensors</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">886ce814ed54c4bd6850e2216d5f198c49475210f8690f45dc63365d9aff3177  llama-65b-4bit/llama-65b-4bit.safetensors</span><br></span></code></pre><div class="buttonGroup_tnuT"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_tmcC" aria-hidden="true"><svg class="copyButtonIcon_Azkd" viewBox="0 0 24 24"><path d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg class="copyButtonSuccessIcon_pt5v" viewBox="0 0 24 24"><path d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p><a href="https://github.com/oobabooga/text-generation-webui/pull/530#issuecomment-1483891617" target="_blank" rel="noopener noreferrer">Torrent source and more information</a></p><h2 class="anchor anchorWithStickyNavbar_KJCY" id="llama-quantized-4-bit-weights-gptq-format-with-groupsize-128">LLaMA quantized 4-bit weights (<a href="https://github.com/qwopqwop200/GPTQ-for-LLaMa" target="_blank" rel="noopener noreferrer">GPTQ</a> format with groupsize 128)<a class="hash-link" href="#llama-quantized-4-bit-weights-gptq-format-with-groupsize-128" title="Direct link to heading">​</a></h2><h4 class="anchor anchorWithStickyNavbar_KJCY" id="2023-03-26-torrent-magnet-1"><a href="magnet:?xt=urn:btih:88f7d9d2460ffcaf78b21e83012de00939eacb65&amp;dn=LLaMA-HF-4bit-128g&amp;tr=http%3a%2f%2fbt2.archive.org%3a6969%2fannounce&amp;tr=http%3a%2f%2fbt1.archive.org%3a6969%2fannounce" target="_blank" rel="noopener noreferrer">2023-03-26 torrent magnet</a><a class="hash-link" href="#2023-03-26-torrent-magnet-1" title="Direct link to heading">​</a></h4><p>!!! info <a href="https://github.com/oobabooga/text-generation-webui/wiki/LLaMA-model#4-bit-mode" target="_blank" rel="noopener noreferrer">Tutorial link for Text generation web UI</a>
<code>Groupsize 128</code> is a better choice for the 13B, 33B and 65B models, according to <a href="https://github.com/oobabooga/text-generation-webui/pull/530#issuecomment-1483941105" target="_blank" rel="noopener noreferrer">this</a>.</p><p>SHA256 checksums:</p><div class="language-text codeBlockContainer_eErV theme-code-block" style="--prism-color:#bfc7d5;--prism-background-color:#292d3e"><div class="codeBlockContent_UzAP"><pre tabindex="0" class="prism-code language-text codeBlock_CYhB thin-scrollbar"><code class="codeBlockLines__AHC"><span class="token-line" style="color:#bfc7d5"><span class="token plain">ed8ec9c9f0ebb83210157ad0e3c5148760a4e9fd2acfb02cf00f8f2054d2743b  llama-7b-4bit-128g/llama-7b-4bit-128g.safetensors</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">d3073ef1a2c0b441f95a5d4f8a5aa3b82884eef45d8997270619cb29bcc994b8  llama-13b-4bit-128g/llama-13b-4bit-128g.safetensors</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">8b7d75d562938823c4503b956cb4b8af6ac0a5afbce2278566cc787da0f8f682  llama-30b-4bit-128g/llama-30b-4bit-128g.safetensors</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">f1418091e3307611fb0a213e50a0f52c80841b9c4bcba67abc1f6c64c357c850  llama-65b-4bit-128g/llama-65b-4bit-128g.safetensors</span><br></span></code></pre><div class="buttonGroup_tnuT"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_tmcC" aria-hidden="true"><svg class="copyButtonIcon_Azkd" viewBox="0 0 24 24"><path d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg class="copyButtonSuccessIcon_pt5v" viewBox="0 0 24 24"><path d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p><a href="https://github.com/oobabooga/text-generation-webui/pull/530#issuecomment-1483941105" target="_blank" rel="noopener noreferrer">Torrent source and more information</a></p><h2 class="anchor anchorWithStickyNavbar_KJCY" id="alpaca-quantized-4-bit-weights-gptq-format-with-groupsize-128">Alpaca quantized 4-bit weights (<a href="https://github.com/qwopqwop200/GPTQ-for-LLaMa" target="_blank" rel="noopener noreferrer">GPTQ</a> format with groupsize 128)<a class="hash-link" href="#alpaca-quantized-4-bit-weights-gptq-format-with-groupsize-128" title="Direct link to heading">​</a></h2><table><thead><tr><th>Model</th><th>Download</th></tr></thead><tbody><tr><td>LLaMA 7B fine-tune from <a href="https://huggingface.co/ozcur/alpaca-native-4bit" target="_blank" rel="noopener noreferrer">ozcur/alpaca-native-4bit</a> as safetensors</td><td><a href="magnet:?xt=urn:btih:90674fd4a3672c6eae5bf994634109bb75429e6b&amp;dn=Alpaca-7B-GPTQ-4bit-128g-native-finetune_2023-03-29&amp;tr=udp%3a%2f%2fopentracker.i2p.rocks%3a6969%2fannounce&amp;tr=udp%3a%2f%2ftracker.altrosky.nl%3a6969%2fannounce&amp;tr=udp%3a%2f%2ftracker-udp.gbitt.info%3a80%2fannounce&amp;tr=udp%3a%2f%2ftracker.opentrackr.org%3a1337%2fannounce&amp;tr=udp%3a%2f%2ftracker.skynetcloud.site%3a6969%2fannounce&amp;tr=udp%3a%2f%2ftracker2.dler.org%3a80%2fannounce&amp;tr=udp%3a%2f%2ftracker.monitorit4.me%3a6969%2fannounce&amp;tr=udp%3a%2f%2ftracker.lelux.fi%3a6969%2fannounce&amp;tr=udp%3a%2f%2ftracker1.bt.moack.co.kr%3a80%2fannounce&amp;tr=udp%3a%2f%2ftracker.torrent.eu.org%3a451%2fannounce&amp;tr=udp%3a%2f%2f9.rarbg.com%3a2810%2fannounce&amp;tr=udp%3a%2f%2ftracker.theoks.net%3a6969%2fannounce&amp;tr=udp%3a%2f%2ftracker.moeking.me%3a6969%2fannounce&amp;tr=udp%3a%2f%2ftracker.tiny-vps.com%3a6969%2fannounce&amp;tr=udp%3a%2f%2ftracker.openbittorrent.com%3a6969%2fannounce&amp;tr=http%3a%2f%2ftracker.openbittorrent.com%3a80%2fannounce&amp;tr=udp%3a%2f%2ftracker.dler.org%3a6969%2fannounce&amp;tr=https%3a%2f%2fopentracker.i2p.rocks%3a443%2fannounce" target="_blank" rel="noopener noreferrer">2023-03-29 torrent magnet</a></td></tr><tr><td>LLaMA 33B merged with <a href="https://huggingface.co/baseten/alpaca-30b" target="_blank" rel="noopener noreferrer">baseten/alpaca-30b</a> LoRA by <a href="https://desuarchive.org/g/thread/92351574/#q92356537" target="_blank" rel="noopener noreferrer">an anon</a></td><td><a href="magnet:?xt=urn:btih:81cf9b528cc80e390323f9ec50d4dfb4debcb490&amp;dn=Alpaca%2030B%204bit%20groupsize%20128&amp;tr=http%3A%2F%2Fbt2.archive.org%3A6969%2Fannounce" target="_blank" rel="noopener noreferrer">2023-03-26 torrent magnet</a> <!-- -->|<!-- --> <a href="https://rentry.org/544p2#llama-33b" target="_blank" rel="noopener noreferrer">extra config files</a></td></tr></tbody></table><p>!!! info <a href="https://github.com/oobabooga/text-generation-webui/wiki/LLaMA-model#4-bit-mode" target="_blank" rel="noopener noreferrer">Tutorial link for Text generation web UI</a></p><p>SHA256 checksums:</p><div class="language-text codeBlockContainer_eErV theme-code-block" style="--prism-color:#bfc7d5;--prism-background-color:#292d3e"><div class="codeBlockContent_UzAP"><pre tabindex="0" class="prism-code language-text codeBlock_CYhB thin-scrollbar"><code class="codeBlockLines__AHC"><span class="token-line" style="color:#bfc7d5"><span class="token plain">17d6ba8f83be89f8dfa05cd4720cdd06b4d32c3baed79986e3ba1501b2305530  Alpaca-7B-GPTQ-4bit-128g-native-finetune_2023-03-29/alpaca-7b-4bit-128g-native-finetune.safetensors</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">a2f8d202ce61b1b612afe08c11f97133c1d56076d65391e738b1ab57c854ee05  Alpaca-30B-4bit-128g/alpaca-30b-hf-4bit.safetensors</span><br></span></code></pre><div class="buttonGroup_tnuT"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_tmcC" aria-hidden="true"><svg class="copyButtonIcon_Azkd" viewBox="0 0 24 24"><path d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg class="copyButtonSuccessIcon_pt5v" viewBox="0 0 24 24"><path d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><h2 class="anchor anchorWithStickyNavbar_KJCY" id="vicuna-13b-quantized-4-bit--8-bit-weights-gptq-format-with-groupsize-128">Vicuna 13B quantized 4-bit &amp; 8-bit weights (<a href="https://github.com/qwopqwop200/GPTQ-for-LLaMa" target="_blank" rel="noopener noreferrer">GPTQ</a> format with groupsize 128)<a class="hash-link" href="#vicuna-13b-quantized-4-bit--8-bit-weights-gptq-format-with-groupsize-128" title="Direct link to heading">​</a></h2><h5 class="anchor anchorWithStickyNavbar_KJCY" id="2023-04-03-torrent-magnet-2"><a href="magnet:?xt=urn:btih:f67d372a01c0b8e0162931623d6c55a5e6f34921&amp;dn=Vicuna-13B-quantized-128g&amp;tr=http%3a%2f%2fbt2.archive.org%3a6969%2fannounce" target="_blank" rel="noopener noreferrer">2023-04-03 torrent magnet</a><a class="hash-link" href="#2023-04-03-torrent-magnet-2" title="Direct link to heading">​</a></h5><p>!!! info <a href="https://github.com/oobabooga/text-generation-webui/wiki/LLaMA-model#4-bit-mode" target="_blank" rel="noopener noreferrer">Tutorial link for Text generation web UI</a></p><p><a href="https://desuarchive.org/g/thread/92531914#92536953" target="_blank" rel="noopener noreferrer">Torrent source</a>
<a href="https://rentry.org/544p2#llama-13b" target="_blank" rel="noopener noreferrer">Extra config files</a></p></div><footer class="theme-doc-footer docusaurus-mt-lg"><div class="theme-doc-footer-edit-meta-row row"><div class="col"><a href="https://github.com/wenerme/wener/edit/master/notes/../notes/ai/llm/llama.md" target="_blank" rel="noreferrer noopener" class="theme-edit-this-page"><svg fill="currentColor" height="20" width="20" viewBox="0 0 40 40" class="iconEdit_BDD2" aria-hidden="true"><g><path d="m34.5 11.7l-3 3.1-6.3-6.3 3.1-3q0.5-0.5 1.2-0.5t1.1 0.5l3.9 3.9q0.5 0.4 0.5 1.1t-0.5 1.2z m-29.5 17.1l18.4-18.5 6.3 6.3-18.4 18.4h-6.3v-6.2z"></path></g></svg>Edit this page</a></div><div class="col lastUpdated_qlge"><span class="theme-last-updated">Last updated<!-- --> on <b><time datetime="2023-05-21T10:51:47.000Z">May 21, 2023</time></b> by <b>wener</b></span></div></div></footer></article><nav class="pagination-nav docusaurus-mt-lg" aria-label="Docs pages navigation"><a class="pagination-nav__link pagination-nav__link--prev" href="/notes/ai/llm/alpaca"><div class="pagination-nav__sublabel">Previous</div><div class="pagination-nav__label">Alpaca</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/notes/ai/ml/deepspeech"><div class="pagination-nav__sublabel">Next</div><div class="pagination-nav__label">DeepSpeech</div></a></nav></div></div><div class="col col--3"><div class="tableOfContents_pluA thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#changelog-mdy" class="table-of-contents__link toc-highlight">Changelog (MDY)</a></li><li><a href="#4-bit-gpu-model-requirements" class="table-of-contents__link toc-highlight">4-bit GPU Model Requirements</a></li><li><a href="#4-bit-cpullamacpp-ram-requirements" class="table-of-contents__link toc-highlight">4-bit CPU/llama.cpp RAM Requirements</a></li><li><a href="#llama-16-bit-weights" class="table-of-contents__link toc-highlight">LLaMA 16-bit Weights</a></li><li><a href="#llama-4-bit-weights" class="table-of-contents__link toc-highlight">LLaMA 4-bit Weights</a></li><li><a href="#wizardlm-13b-uncensored-05102023" class="table-of-contents__link toc-highlight">WizardLM 13B Uncensored (05/10/2023)</a></li><li><a href="#bluemoonrp-13b-05072023" class="table-of-contents__link toc-highlight">BluemoonRP 13B (05/07/2023)</a></li><li><a href="#vicuna-13b-cocktail-05072023" class="table-of-contents__link toc-highlight">Vicuna 13B Cocktail (05/07/2023)</a></li><li><a href="#gpt4-x-alpacadente2-30b-05052023" class="table-of-contents__link toc-highlight">GPT4-x-AlpacaDente2-30B (05/05/2023)</a></li><li><a href="#vicuna-13b-free-v11-05012023" class="table-of-contents__link toc-highlight">Vicuna 13B Free v1.1 (05/01/2023)</a></li><li><a href="#pygmalionmetharme-7b-04302023" class="table-of-contents__link toc-highlight">Pygmalion/Metharme 7B (04/30/2023)</a></li><li><a href="#gpt4-x-alpasta-30b-04292023" class="table-of-contents__link toc-highlight">GPT4-X-Alpasta 30B (04/29/2023)</a></li><li><a href="#openassistant-llama-30b-sft-6-04232023" class="table-of-contents__link toc-highlight">OpenAssistant LLaMa 30B SFT 6 (04/23/2023)</a></li><li><a href="#supercot-04222023" class="table-of-contents__link toc-highlight">SuperCOT (04/22/2023)</a></li><li><a href="#previous-model-list" class="table-of-contents__link toc-highlight">Previous Model List</a></li><li><a href="#llama-quantized-4-bit-weights-ggml-q4_0" class="table-of-contents__link toc-highlight">LLaMA quantized 4-bit weights (ggml q4_0)</a></li><li><a href="#alpaca-quantized-4-bit-weights-ggml-q4_0" class="table-of-contents__link toc-highlight">Alpaca quantized 4-bit weights (ggml q4_0)</a></li><li><a href="#gpt4all-7b-quantized-4-bit-weights-ggml-q4_0" class="table-of-contents__link toc-highlight">GPT4All 7B quantized 4-bit weights (ggml q4_0)</a></li><li><a href="#gpt4-x-alpaca-13b-quantized-4-bit-weights-ggml-q4_0" class="table-of-contents__link toc-highlight">GPT4 x Alpaca 13B quantized 4-bit weights (ggml q4_0)</a></li><li><a href="#gpt4-x-alpaca-13b-quantized-4-bit-weights-ggml-q4_1-from-gptq-with-groupsize-128" class="table-of-contents__link toc-highlight">GPT4 x Alpaca 13B quantized 4-bit weights (ggml q4_1 from GPTQ with groupsize 128)</a></li><li><a href="#vicuna-13b-quantized-4-bit-weights-ggml-q4_0" class="table-of-contents__link toc-highlight">Vicuna 13B quantized 4-bit weights (ggml q4_0)</a></li><li><a href="#openassistant-llama-13b-quantized-4-bit-weights-ggml-q4_0--q4_1" class="table-of-contents__link toc-highlight">OpenAssistant LLaMA 13B quantized 4-bit weights (ggml q4_0 &amp; q4_1)</a></li><li><a href="#llama-float16-weights" class="table-of-contents__link toc-highlight">LLaMA float16 weights</a></li><li><a href="#vicuna-13b-float16-weights" class="table-of-contents__link toc-highlight">Vicuna 13B float16 weights</a></li><li><a href="#llama-quantized-4-bit-weights-gptq-format-without-groupsize" class="table-of-contents__link toc-highlight">LLaMA quantized 4-bit weights (GPTQ format without groupsize)</a></li><li><a href="#llama-quantized-4-bit-weights-gptq-format-with-groupsize-128" class="table-of-contents__link toc-highlight">LLaMA quantized 4-bit weights (GPTQ format with groupsize 128)</a></li><li><a href="#alpaca-quantized-4-bit-weights-gptq-format-with-groupsize-128" class="table-of-contents__link toc-highlight">Alpaca quantized 4-bit weights (GPTQ format with groupsize 128)</a></li><li><a href="#vicuna-13b-quantized-4-bit--8-bit-weights-gptq-format-with-groupsize-128" class="table-of-contents__link toc-highlight">Vicuna 13B quantized 4-bit &amp; 8-bit weights (GPTQ format with groupsize 128)</a></li></ul></div></div></div></div></main></div></div><footer class="footer footer--dark"><div class="container container-fluid"><div class="row footer__links"><div class="col footer__col"><div class="footer__title">笔记</div><ul class="footer__items clean-list"><li class="footer__item"><a class="footer__link-item" href="/notes/java">Java</a></li><li class="footer__item"><a class="footer__link-item" href="/notes/os/alpine">AlpineLinux</a></li><li class="footer__item"><a class="footer__link-item" href="/notes/devops/kubernetes">Kubernates</a></li><li class="footer__item"><a class="footer__link-item" href="/notes/voip">VoIP</a></li></ul></div><div class="col footer__col"><div class="footer__title">Projects</div><ul class="footer__items clean-list"><li class="footer__item">
              <div>
              <a class="footer__link-item" href="https://github.com/wenerme/wener">Wener</a>
              -
              <a class="footer__link-item" href="https://github.com/wenerme/wener/actions" title="wenerme/wener - ci">
              <img style="vertical-align: middle;opacity: .4;" src="https://github.com/wenerme/wener/workflows/Build/badge.svg">
              </a>
              </div>
              </li><li class="footer__item"><a href="https://apis.wener.me" target="_blank" rel="noopener noreferrer" class="footer__link-item">Wener&#x27;s Apis<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_QEvt"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li></ul></div><div class="col footer__col"><div class="footer__title">Social</div><ul class="footer__items clean-list"><li class="footer__item"><a class="footer__link-item" href="/story">Blog</a></li><li class="footer__item"><a href="https://github.com/wenerme" target="_blank" rel="noopener noreferrer" class="footer__link-item">GitHub</a></li><li class="footer__item"><a href="https://twitter.com/wenerme" target="_blank" rel="noopener noreferrer" class="footer__link-item">Twitter</a></li></ul></div></div><div class="footer__bottom text--center"><div class="margin-bottom--sm"><img src="/img/wener-logo.svg" alt="Wener Site" class="themedImage_QM0D themedImage--light_s8Fn footer__logo"><img src="/img/wener-logo.svg" alt="Wener Site" class="themedImage_QM0D themedImage--dark_Yfiw footer__logo"></div><div class="footer__copyright">Copyright © 1992-2023 Wener - <img alt="cc-by-sa-4.0" src="https://mirrors.creativecommons.org/presskit/buttons/80x15/svg/by-sa.svg"> - Build @2023-06-16 21:10</div></div></div></footer></div>
<script src="/assets/js/runtime~main.1619f0f2.js"></script>
<script src="/assets/js/main.8cb596bc.js"></script>
</body>
</html>