"use strict";(self.webpackChunkwener_website=self.webpackChunkwener_website||[]).push([[21042],{49613:function(e,a,t){t.d(a,{Zo:function(){return l},kt:function(){return g}});var n=t(59496);function r(e,a,t){return a in e?Object.defineProperty(e,a,{value:t,enumerable:!0,configurable:!0,writable:!0}):e[a]=t,e}function o(e,a){var t=Object.keys(e);if(Object.getOwnPropertySymbols){var n=Object.getOwnPropertySymbols(e);a&&(n=n.filter((function(a){return Object.getOwnPropertyDescriptor(e,a).enumerable}))),t.push.apply(t,n)}return t}function c(e){for(var a=1;a<arguments.length;a++){var t=null!=arguments[a]?arguments[a]:{};a%2?o(Object(t),!0).forEach((function(a){r(e,a,t[a])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(t)):o(Object(t)).forEach((function(a){Object.defineProperty(e,a,Object.getOwnPropertyDescriptor(t,a))}))}return e}function f(e,a){if(null==e)return{};var t,n,r=function(e,a){if(null==e)return{};var t,n,r={},o=Object.keys(e);for(n=0;n<o.length;n++)t=o[n],a.indexOf(t)>=0||(r[t]=e[t]);return r}(e,a);if(Object.getOwnPropertySymbols){var o=Object.getOwnPropertySymbols(e);for(n=0;n<o.length;n++)t=o[n],a.indexOf(t)>=0||Object.prototype.propertyIsEnumerable.call(e,t)&&(r[t]=e[t])}return r}var i=n.createContext({}),p=function(e){var a=n.useContext(i),t=a;return e&&(t="function"==typeof e?e(a):c(c({},a),e)),t},l=function(e){var a=p(e.components);return n.createElement(i.Provider,{value:a},e.children)},u={inlineCode:"code",wrapper:function(e){var a=e.children;return n.createElement(n.Fragment,{},a)}},d=n.forwardRef((function(e,a){var t=e.components,r=e.mdxType,o=e.originalType,i=e.parentName,l=f(e,["components","mdxType","originalType","parentName"]),d=p(t),g=r,m=d["".concat(i,".").concat(g)]||d[g]||u[g]||o;return t?n.createElement(m,c(c({ref:a},l),{},{components:t})):n.createElement(m,c({ref:a},l))}));function g(e,a){var t=arguments,r=a&&a.mdxType;if("string"==typeof e||r){var o=t.length,c=new Array(o);c[0]=d;var f={};for(var i in a)hasOwnProperty.call(a,i)&&(f[i]=a[i]);f.originalType=e,f.mdxType="string"==typeof e?e:r,c[1]=f;for(var p=2;p<o;p++)c[p]=t[p];return n.createElement.apply(null,c)}return n.createElement.apply(null,t)}d.displayName="MDXCreateElement"},26328:function(e,a,t){t.r(a),t.d(a,{assets:function(){return b},contentTitle:function(){return g},default:function(){return h},frontMatter:function(){return d},metadata:function(){return m},toc:function(){return k}});var n=t(49613),r=Object.defineProperty,o=Object.defineProperties,c=Object.getOwnPropertyDescriptors,f=Object.getOwnPropertySymbols,i=Object.prototype.hasOwnProperty,p=Object.prototype.propertyIsEnumerable,l=(e,a,t)=>a in e?r(e,a,{enumerable:!0,configurable:!0,writable:!0,value:t}):e[a]=t,u=(e,a)=>{for(var t in a||(a={}))i.call(a,t)&&l(e,t,a[t]);if(f)for(var t of f(a))p.call(a,t)&&l(e,t,a[t]);return e};const d={title:"LLaMa"},g="llama",m={unversionedId:"ai/llama",id:"ai/llama",title:"LLaMa",description:"- LLaMA-7B, 3.5GB, 6GB",source:"@site/../notes/ai/llama.md",sourceDirName:"ai",slug:"/ai/llama",permalink:"/notes/ai/llama",draft:!1,editUrl:"https://github.com/wenerme/wener/edit/master/notes/../notes/ai/llama.md",tags:[],version:"current",lastUpdatedBy:"wener",lastUpdatedAt:1681042995,formattedLastUpdatedAt:"Apr 9, 2023",frontMatter:{title:"LLaMa"},sidebar:"docs",previous:{title:"GPT Awesome",permalink:"/notes/ai/gpt/awesome"},next:{title:"DeepSpeech",permalink:"/notes/ai/ml/deepspeech"}},b={},k=[{value:"LLaMA quantized 4-bit weights (ggml q4_0)",id:"llama-quantized-4-bit-weights-ggml-q4_0",level:2},{value:"2023-03-31 torrent magnet",id:"2023-03-31-torrent-magnet",level:4},{value:"Alpaca quantized 4-bit weights (ggml q4_0)",id:"alpaca-quantized-4-bit-weights-ggml-q4_0",level:2},{value:"GPT4All 7B quantized 4-bit weights (ggml q4_0)",id:"gpt4all-7b-quantized-4-bit-weights-ggml-q4_0",level:2},{value:"2023-03-31 torrent magnet",id:"2023-03-31-torrent-magnet-1",level:4},{value:"GPT4 x Alpaca 13B quantized 4-bit weights (ggml q4_0)",id:"gpt4-x-alpaca-13b-quantized-4-bit-weights-ggml-q4_0",level:2},{value:"2023-04-01 torrent magnet",id:"2023-04-01-torrent-magnet",level:4},{value:"GPT4 x Alpaca 13B quantized 4-bit weights (ggml q4_1 from GPTQ with groupsize 128)",id:"gpt4-x-alpaca-13b-quantized-4-bit-weights-ggml-q4_1-from-gptq-with-groupsize-128",level:2},{value:"2023-04-01 torrent magnet",id:"2023-04-01-torrent-magnet-1",level:4},{value:"Vicuna 13B quantized 4-bit weights (ggml q4_0)",id:"vicuna-13b-quantized-4-bit-weights-ggml-q4_0",level:2},{value:"2023-04-03 torrent magnet",id:"2023-04-03-torrent-magnet",level:4},{value:"OpenAssistant LLaMA 13B quantized 4-bit weights (ggml q4_0 &amp; q4_1)",id:"openassistant-llama-13b-quantized-4-bit-weights-ggml-q4_0--q4_1",level:2},{value:"2023-04-07 torrent magnet | HuggingFace Hub direct download",id:"2023-04-07-torrent-magnet--huggingface-hub-direct-download",level:4},{value:"LLaMA float16 weights",id:"llama-float16-weights",level:2},{value:"2023-03-26 torrent magnet | HuggingFace Hub direct downloads",id:"2023-03-26-torrent-magnet--huggingface-hub-direct-downloads",level:4},{value:"Vicuna 13B float16 weights",id:"vicuna-13b-float16-weights",level:2},{value:"2023-04-03 torrent magnet",id:"2023-04-03-torrent-magnet-1",level:4},{value:"LLaMA quantized 4-bit weights (GPTQ format without groupsize)",id:"llama-quantized-4-bit-weights-gptq-format-without-groupsize",level:2},{value:"2023-03-26 torrent magnet",id:"2023-03-26-torrent-magnet",level:4},{value:"LLaMA quantized 4-bit weights (GPTQ format with groupsize 128)",id:"llama-quantized-4-bit-weights-gptq-format-with-groupsize-128",level:2},{value:"2023-03-26 torrent magnet",id:"2023-03-26-torrent-magnet-1",level:4},{value:"Alpaca quantized 4-bit weights (GPTQ format with groupsize 128)",id:"alpaca-quantized-4-bit-weights-gptq-format-with-groupsize-128",level:2},{value:"Vicuna 13B quantized 4-bit &amp; 8-bit weights (GPTQ format with groupsize 128)",id:"vicuna-13b-quantized-4-bit--8-bit-weights-gptq-format-with-groupsize-128",level:2},{value:"2023-04-03 torrent magnet",id:"2023-04-03-torrent-magnet-2",level:5}],s={toc:k};function h(e){var a,t=e,{components:r}=t,l=((e,a)=>{var t={};for(var n in e)i.call(e,n)&&a.indexOf(n)<0&&(t[n]=e[n]);if(null!=e&&f)for(var n of f(e))a.indexOf(n)<0&&p.call(e,n)&&(t[n]=e[n]);return t})(t,["components"]);return(0,n.kt)("wrapper",(a=u(u({},s),l),o(a,c({components:r,mdxType:"MDXLayout"}))),(0,n.kt)("h1",u({},{id:"llama"}),"llama"),(0,n.kt)("ul",null,(0,n.kt)("li",{parentName:"ul"},"LLaMA-7B, 3.5GB, 6GB"),(0,n.kt)("li",{parentName:"ul"},"LLaMA-13B, 6.5GB, 10GB"),(0,n.kt)("li",{parentName:"ul"},"LLaMA-30B, 15.8GB, 20GB"),(0,n.kt)("li",{parentName:"ul"},"LLaMA-65B, 31.2GB, 40GB"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",u({parentName:"li"},{href:"https://news.ycombinator.com/item?id=35107058"}),"https://news.ycombinator.com/item?id=35107058"))),(0,n.kt)("pre",null,(0,n.kt)("code",u({parentName:"pre"},{className:"language-bash"}),'# py for\napk add \\\n  gcc g++ python3 py3-pip musl-dev cmake make pkgconf build-base \\\n  git openssh-client binutils coreutils util-linux findutils sed grep tar wget curl neofetch \\\n  rust cargo python3-dev openssl-dev linux-headers\n\n# llama.cpp\n# =========\ngit clone https://github.com/ggerganov/llama.cpp.git\ncd llama.cpp\nmake -j\n\n./main -m ./models/7B/ggml-model-q4_0.bin -p "Building a website can be done in 10 simple steps:" -n 512\n./main -m ./models/7B/ggml-model-q4_0.bin --file prompts/alpaca.txt --instruct --ctx_size 2048 --keep -1\n\n./main -m ./models/ggml-alpaca-7b-q4.bin --color -f ./prompts/alpaca.txt -ins -b 256 --top_k 10000 --temp 0.2 --repeat_penalty 1 -t 7\n\n# https://github.com/ymcui/Chinese-LLaMA-Alpaca\n# =========\napk add rust cargo python3-dev openssl-dev cmake linux-headers\npip install git+https://github.com/huggingface/transformers\npip install sentencepiece\npip install torch --index-url https://download.pytorch.org/whl/cpu\npip install peft\n\ngit clone https://github.com/huggingface/transformers\n\n# musl pthread_attr_setaffinity_np\npython ./transformers/src/transformers/models/llama/convert_llama_weights_to_hf.py \\\n    --input_dir /ml/models/LLaMA \\\n    --model_size 7B \\\n    --output_dir /ml/models/LLaMA-hf\n')),(0,n.kt)("hr",null),(0,n.kt)("ul",null,(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",u({parentName:"li"},{href:"https://rentry.org/nur779"}),"https://rentry.org/nur779"))),(0,n.kt)("h1",u({},{id:"models-for-llamacpp-ggml-format"}),"Models for ",(0,n.kt)("a",u({parentName:"h1"},{href:"https://github.com/ggerganov/llama.cpp"}),"llama.cpp")," (",(0,n.kt)("a",u({parentName:"h1"},{href:"https://github.com/ggerganov/ggml"}),"ggml")," format)"),(0,n.kt)("h2",u({},{id:"llama-quantized-4-bit-weights-ggml-q4_0"}),"LLaMA quantized 4-bit weights (ggml q4_0)"),(0,n.kt)("h4",u({},{id:"2023-03-31-torrent-magnet"}),(0,n.kt)("a",u({parentName:"h4"},{href:"magnet:?xt=urn:btih:481dee5424b7024433504803a90efd32dae40fdf&dn=LLaMA-ggml-4bit_2023-03-31&tr=udp%3a%2f%2ftracker1.bt.moack.co.kr%3a80%2fannounce&tr=udp%3a%2f%2ftracker.torrent.eu.org%3a451%2fannounce&tr=udp%3a%2f%2ftracker.altrosky.nl%3a6969%2fannounce&tr=udp%3a%2f%2fopentracker.i2p.rocks%3a6969%2fannounce&tr=udp%3a%2f%2ftracker.opentrackr.org%3a1337%2fannounce&tr=https%3a%2f%2fopentracker.i2p.rocks%3a443%2fannounce&tr=udp%3a%2f%2ftracker.theoks.net%3a6969%2fannounce&tr=udp%3a%2f%2ftracker-udp.gbitt.info%3a80%2fannounce&tr=udp%3a%2f%2ftracker.tiny-vps.com%3a6969%2fannounce&tr=udp%3a%2f%2ftracker.moeking.me%3a6969%2fannounce&tr=udp%3a%2f%2f9.rarbg.com%3a2810%2fannounce&tr=udp%3a%2f%2ftracker.openbittorrent.com%3a6969%2fannounce&tr=udp%3a%2f%2ftracker.monitorit4.me%3a6969%2fannounce&tr=udp%3a%2f%2ftracker.dler.org%3a6969%2fannounce&tr=http%3a%2f%2ftracker.openbittorrent.com%3a80%2fannounce&tr=udp%3a%2f%2ftracker2.dler.org%3a80%2fannounce"}),"2023-03-31 torrent magnet")),(0,n.kt)("p",null,"!!! info ",(0,n.kt)("a",u({parentName:"p"},{href:"https://github.com/ggerganov/llama.cpp#interactive-mode"}),"Tutorial link for llama.cpp"),"\n!!! info ",(0,n.kt)("a",u({parentName:"p"},{href:"https://github.com/LostRuins/koboldcpp#usage"}),"Tutorial link for koboldcpp")),(0,n.kt)("p",null,"SHA256 checksums:"),(0,n.kt)("pre",null,(0,n.kt)("code",u({parentName:"pre"},{className:"language-text"}),"2dad53e70ca521fedcf9f9be5c26c15df602487a9c008bdafbb2bf8f946b6bf0  llama-7b-ggml-q4_0/ggml-model-q4_0.bin\n9cd4d6c1f5f42d5abf529c51bde3303991fba912ab8ed452adfd7c97a4be77d7  llama-13b-ggml-q4_0/ggml-model-q4_0.bin\ndaefbc6b1b644a75be0286ef865253ab3786e96a2c1bca8b71216b1751eee63e  llama-33b-ggml-q4_0/ggml-model-q4_0.bin\nd58a29c8403ecbd14258bbce07d90894fc5a8be25b9d359463c18f9f2ef96eb6  llama-65b-ggml-q4_0/ggml-model-q4_0.bin\n")),(0,n.kt)("p",null,"ggml model file magic: ",(0,n.kt)("inlineCode",{parentName:"p"},"0x67676a74")," (",(0,n.kt)("inlineCode",{parentName:"p"},"ggjt")," in hex)\nggml model file version: ",(0,n.kt)("inlineCode",{parentName:"p"},"1")),(0,n.kt)("h2",u({},{id:"alpaca-quantized-4-bit-weights-ggml-q4_0"}),"Alpaca quantized 4-bit weights (ggml q4_0)"),(0,n.kt)("table",null,(0,n.kt)("thead",{parentName:"table"},(0,n.kt)("tr",{parentName:"thead"},(0,n.kt)("th",u({parentName:"tr"},{align:null}),"Model"),(0,n.kt)("th",u({parentName:"tr"},{align:null}),"Download"))),(0,n.kt)("tbody",{parentName:"table"},(0,n.kt)("tr",{parentName:"tbody"},(0,n.kt)("td",u({parentName:"tr"},{align:null}),"LLaMA 7B fine-tune from ",(0,n.kt)("a",u({parentName:"td"},{href:"https://huggingface.co/chavinlo/alpaca-native/tree/062111ff2af99db24f466562b8eb7e7e4ad7566d"}),"chavinlo/alpaca-native")),(0,n.kt)("td",u({parentName:"tr"},{align:null}),(0,n.kt)("a",u({parentName:"td"},{href:"magnet:?xt=urn:btih:d931a826b59443f4e543c18a25009b0ce8eabf39&dn=Alpaca-7B-ggml-4bit-native-finetune_2023-03-31&tr=udp%3a%2f%2ftracker.openbittorrent.com%3a6969%2fannounce&tr=udp%3a%2f%2ftracker.altrosky.nl%3a6969%2fannounce&tr=udp%3a%2f%2ftracker.dler.org%3a6969%2fannounce&tr=udp%3a%2f%2ftracker1.bt.moack.co.kr%3a80%2fannounce&tr=udp%3a%2f%2ftracker.moeking.me%3a6969%2fannounce&tr=udp%3a%2f%2ftracker2.dler.org%3a80%2fannounce&tr=udp%3a%2f%2ftracker.theoks.net%3a6969%2fannounce&tr=udp%3a%2f%2ftracker.tiny-vps.com%3a6969%2fannounce&tr=udp%3a%2f%2ftracker-udp.gbitt.info%3a80%2fannounce&tr=udp%3a%2f%2fopentracker.i2p.rocks%3a6969%2fannounce&tr=https%3a%2f%2fopentracker.i2p.rocks%3a443%2fannounce&tr=http%3a%2f%2ftracker.openbittorrent.com%3a80%2fannounce&tr=udp%3a%2f%2ftracker.torrent.eu.org%3a451%2fannounce&tr=udp%3a%2f%2f9.rarbg.com%3a2810%2fannounce&tr=udp%3a%2f%2ftracker.opentrackr.org%3a1337%2fannounce&tr=udp%3a%2f%2ftracker.monitorit4.me%3a6969%2fannounce"}),"2023-03-31 torrent magnet"))),(0,n.kt)("tr",{parentName:"tbody"},(0,n.kt)("td",u({parentName:"tr"},{align:null}),"LLaMA 7B merged with ",(0,n.kt)("a",u({parentName:"td"},{href:"https://huggingface.co/tloen/alpaca-lora-7b/tree/28801eabf63a125cee9e46d8073fb13c7c8bd8b9"}),"tloen/alpaca-lora-7b")," LoRA"),(0,n.kt)("td",u({parentName:"tr"},{align:null}),(0,n.kt)("a",u({parentName:"td"},{href:"magnet:?xt=urn:btih:694e206c1ce2780db673bdc2ecee78abcf228324&dn=Alpaca-7B-ggml-4bit-LoRA-merged_2023-03-31&tr=udp%3a%2f%2ftracker1.bt.moack.co.kr%3a80%2fannounce&tr=udp%3a%2f%2ftracker.monitorit4.me%3a6969%2fannounce&tr=udp%3a%2f%2ftracker.openbittorrent.com%3a6969%2fannounce&tr=udp%3a%2f%2ftracker.dler.org%3a6969%2fannounce&tr=http%3a%2f%2ftracker.openbittorrent.com%3a80%2fannounce&tr=udp%3a%2f%2ftracker.moeking.me%3a6969%2fannounce&tr=udp%3a%2f%2ftracker-udp.gbitt.info%3a80%2fannounce&tr=udp%3a%2f%2ftracker.theoks.net%3a6969%2fannounce&tr=udp%3a%2f%2fopentracker.i2p.rocks%3a6969%2fannounce&tr=udp%3a%2f%2ftracker.opentrackr.org%3a1337%2fannounce&tr=https%3a%2f%2fopentracker.i2p.rocks%3a443%2fannounce&tr=udp%3a%2f%2ftracker.altrosky.nl%3a6969%2fannounce&tr=udp%3a%2f%2ftracker.tiny-vps.com%3a6969%2fannounce&tr=udp%3a%2f%2ftracker2.dler.org%3a80%2fannounce&tr=udp%3a%2f%2ftracker.torrent.eu.org%3a451%2fannounce&tr=udp%3a%2f%2f9.rarbg.com%3a2810%2fannounce"}),"2023-03-31 torrent magnet"))),(0,n.kt)("tr",{parentName:"tbody"},(0,n.kt)("td",u({parentName:"tr"},{align:null}),"LLaMA 13B merged with ",(0,n.kt)("a",u({parentName:"td"},{href:"https://huggingface.co/chansung/alpaca-lora-13b/tree/abcdddb2778cace16f184dc1dda0ecf21ade23bc"}),"chansung/alpaca-lora-13b")," LoRA"),(0,n.kt)("td",u({parentName:"tr"},{align:null}),(0,n.kt)("a",u({parentName:"td"},{href:"magnet:?xt=urn:btih:31ad0f8e8da5d43bad83eeed94f24cca504330d1&dn=Alpaca-13B-ggml-4bit-LoRA-merged_2023-03-31&tr=udp%3a%2f%2ftracker.openbittorrent.com%3a6969%2fannounce&tr=http%3a%2f%2ftracker.openbittorrent.com%3a80%2fannounce&tr=udp%3a%2f%2f9.rarbg.com%3a2810%2fannounce&tr=udp%3a%2f%2fopentracker.i2p.rocks%3a6969%2fannounce&tr=udp%3a%2f%2ftracker.monitorit4.me%3a6969%2fannounce&tr=https%3a%2f%2fopentracker.i2p.rocks%3a443%2fannounce&tr=udp%3a%2f%2ftracker.moeking.me%3a6969%2fannounce&tr=udp%3a%2f%2ftracker1.bt.moack.co.kr%3a80%2fannounce&tr=udp%3a%2f%2ftracker.opentrackr.org%3a1337%2fannounce&tr=udp%3a%2f%2ftracker.altrosky.nl%3a6969%2fannounce&tr=udp%3a%2f%2ftracker2.dler.org%3a80%2fannounce&tr=udp%3a%2f%2ftracker.theoks.net%3a6969%2fannounce&tr=udp%3a%2f%2ftracker-udp.gbitt.info%3a80%2fannounce&tr=udp%3a%2f%2ftracker.dler.org%3a6969%2fannounce&tr=udp%3a%2f%2ftracker.torrent.eu.org%3a451%2fannounce&tr=udp%3a%2f%2ftracker.tiny-vps.com%3a6969%2fannounce"}),"2023-03-31 torrent magnet"))),(0,n.kt)("tr",{parentName:"tbody"},(0,n.kt)("td",u({parentName:"tr"},{align:null}),"LLaMA 33B merged with ",(0,n.kt)("a",u({parentName:"td"},{href:"https://huggingface.co/chansung/alpaca-lora-30b/tree/bbbc77a38ad00a64780a76d119c783b6dc8200bd"}),"chansung/alpaca-lora-30b")," LoRA"),(0,n.kt)("td",u({parentName:"tr"},{align:null}),(0,n.kt)("a",u({parentName:"td"},{href:"magnet:?xt=urn:btih:1e8681e255ec3078ef84fe4cdecdc7abd8b2b6e5&dn=Alpaca-33B-ggml-4bit-LoRA-merged_2023-03-31&tr=udp%3a%2f%2ftracker-udp.gbitt.info%3a80%2fannounce&tr=udp%3a%2f%2f9.rarbg.com%3a2810%2fannounce&tr=udp%3a%2f%2ftracker.moeking.me%3a6969%2fannounce&tr=udp%3a%2f%2ftracker.tiny-vps.com%3a6969%2fannounce&tr=udp%3a%2f%2ftracker.dler.org%3a6969%2fannounce&tr=udp%3a%2f%2ftracker.monitorit4.me%3a6969%2fannounce&tr=udp%3a%2f%2ftracker.theoks.net%3a6969%2fannounce&tr=udp%3a%2f%2ftracker.opentrackr.org%3a1337%2fannounce&tr=udp%3a%2f%2ftracker2.dler.org%3a80%2fannounce&tr=udp%3a%2f%2ftracker.openbittorrent.com%3a6969%2fannounce&tr=http%3a%2f%2ftracker.openbittorrent.com%3a80%2fannounce&tr=udp%3a%2f%2fopentracker.i2p.rocks%3a6969%2fannounce&tr=https%3a%2f%2fopentracker.i2p.rocks%3a443%2fannounce&tr=udp%3a%2f%2ftracker.torrent.eu.org%3a451%2fannounce&tr=udp%3a%2f%2ftracker1.bt.moack.co.kr%3a80%2fannounce&tr=udp%3a%2f%2ftracker.altrosky.nl%3a6969%2fannounce"}),"2023-03-31 torrent magnet"))))),(0,n.kt)("p",null,"!!! info ",(0,n.kt)("a",u({parentName:"p"},{href:"https://github.com/ggerganov/llama.cpp#instruction-mode-with-alpaca"}),"Tutorial link for llama.cpp"),"\nExample:\n",(0,n.kt)("inlineCode",{parentName:"p"},"./main --model ggml-model-q4_0.bin --file prompts/alpaca.txt --instruct --ctx_size 2048 --keep -1"),"\n!!! info ",(0,n.kt)("a",u({parentName:"p"},{href:"https://github.com/LostRuins/koboldcpp#usage"}),"Tutorial link for koboldcpp")),(0,n.kt)("p",null,"SHA256 checksums:"),(0,n.kt)("pre",null,(0,n.kt)("code",u({parentName:"pre"},{className:"language-text"}),"f5e264b10944c55a84810e8073dfdcd653fa8e47ff50ea043ec071051ac7821d  alpaca-7b-ggml-q4_0-native-finetune/ggml-model-q4_0.bin\nd9777baad5cf6a5d196e70867338d8cc3c7af68c7744e68de839a522983860d7  alpaca-7b-ggml-q4_0-lora-merged/ggml-model-q4_0.bin\n3838aa32651c65948e289374abd71f6feab1a62a4921a648e30d979df86a4af3  alpaca-13b-ggml-q4_0-lora-merged/ggml-model-q4_0.bin\n2267ed1dc0bf0d6d300ba292c25083c7fa5395f3726c7c68a49b2be19a64b349  alpaca-33b-ggml-q4_0-lora-merged/ggml-model-q4_0.bin\n")),(0,n.kt)("p",null,"ggml model file magic: ",(0,n.kt)("inlineCode",{parentName:"p"},"0x67676a74")," (",(0,n.kt)("inlineCode",{parentName:"p"},"ggjt")," in hex)\nggml model file version: ",(0,n.kt)("inlineCode",{parentName:"p"},"1")),(0,n.kt)("h2",u({},{id:"gpt4all-7b-quantized-4-bit-weights-ggml-q4_0"}),"GPT4All 7B quantized 4-bit weights (ggml q4_0)"),(0,n.kt)("h4",u({},{id:"2023-03-31-torrent-magnet-1"}),(0,n.kt)("a",u({parentName:"h4"},{href:"magnet:?xt=urn:btih:04584d8e5799c7838ccb987fae4f183936b9d744&dn=GPT4All-7B-ggml-4bit-lora-merged_2023-03-31&tr=udp%3a%2f%2ftracker1.bt.moack.co.kr%3a80%2fannounce&tr=udp%3a%2f%2ftracker.monitorit4.me%3a6969%2fannounce&tr=udp%3a%2f%2ftracker.theoks.net%3a6969%2fannounce&tr=udp%3a%2f%2f9.rarbg.com%3a2810%2fannounce&tr=udp%3a%2f%2ftracker.opentrackr.org%3a1337%2fannounce&tr=udp%3a%2f%2ftracker.openbittorrent.com%3a6969%2fannounce&tr=http%3a%2f%2ftracker.openbittorrent.com%3a80%2fannounce&tr=udp%3a%2f%2ftracker.tiny-vps.com%3a6969%2fannounce&tr=udp%3a%2f%2ftracker.altrosky.nl%3a6969%2fannounce&tr=udp%3a%2f%2ftracker.dler.org%3a6969%2fannounce&tr=udp%3a%2f%2ftracker2.dler.org%3a80%2fannounce&tr=udp%3a%2f%2ftracker.moeking.me%3a6969%2fannounce&tr=udp%3a%2f%2ftracker-udp.gbitt.info%3a80%2fannounce&tr=udp%3a%2f%2fopentracker.i2p.rocks%3a6969%2fannounce&tr=https%3a%2f%2fopentracker.i2p.rocks%3a443%2fannounce&tr=udp%3a%2f%2ftracker.torrent.eu.org%3a451%2fannounce"}),"2023-03-31 torrent magnet")),(0,n.kt)("p",null,"!!! info ",(0,n.kt)("a",u({parentName:"p"},{href:"https://github.com/ggerganov/llama.cpp#interactive-mode"}),"Tutorial link for llama.cpp"),"\nGPT4All can be used with llama.cpp in the same way as the other ",(0,n.kt)("inlineCode",{parentName:"p"},"ggml")," models.\n!!! info ",(0,n.kt)("a",u({parentName:"p"},{href:"https://github.com/LostRuins/koboldcpp#usage"}),"Tutorial link for koboldcpp")),(0,n.kt)("p",null,"SHA256 checksums:"),(0,n.kt)("pre",null,(0,n.kt)("code",u({parentName:"pre"},{className:"language-text"}),"9f6cd4830a3c45a86147c80a32888e7be8f8a489284c87cdb882a7cfe40940c1  gpt4all-unfiltered-7b-ggml-q4_0-lora-merged/ggml-model-q4_0.bin\nde314c5ee155ac40a03ca3b3be85ba2b02aef9e9f083c411c0b4490689dd047e  gpt4all-7b-ggml-q4_0-lora-merged/ggml-model-q4_0.bin\n")),(0,n.kt)("p",null,"ggml model file magic: ",(0,n.kt)("inlineCode",{parentName:"p"},"0x67676a74")," (",(0,n.kt)("inlineCode",{parentName:"p"},"ggjt")," in hex)\nggml model file version: ",(0,n.kt)("inlineCode",{parentName:"p"},"1")),(0,n.kt)("h2",u({},{id:"gpt4-x-alpaca-13b-quantized-4-bit-weights-ggml-q4_0"}),"GPT4 x Alpaca 13B quantized 4-bit weights (ggml q4_0)"),(0,n.kt)("h4",u({},{id:"2023-04-01-torrent-magnet"}),(0,n.kt)("a",u({parentName:"h4"},{href:"magnet:?xt=urn:btih:f77827abd0cfb77399a0b281a1dbaeac5c386413&dn=GPT4-x-Alpaca-13B-ggml-4bit_2023-04-01&tr=udp%3a%2f%2ftracker.altrosky.nl%3a6969%2fannounce&tr=udp%3a%2f%2ftracker-udp.gbitt.info%3a80%2fannounce&tr=udp%3a%2f%2ftracker.theoks.net%3a6969%2fannounce&tr=udp%3a%2f%2ftracker.moeking.me%3a6969%2fannounce&tr=udp%3a%2f%2ftracker1.bt.moack.co.kr%3a80%2fannounce&tr=udp%3a%2f%2ftracker.openbittorrent.com%3a6969%2fannounce&tr=udp%3a%2f%2fopentracker.i2p.rocks%3a6969%2fannounce&tr=udp%3a%2f%2ftracker.torrent.eu.org%3a451%2fannounce&tr=https%3a%2f%2fopentracker.i2p.rocks%3a443%2fannounce&tr=udp%3a%2f%2ftracker2.dler.org%3a80%2fannounce&tr=udp%3a%2f%2ftracker.dler.org%3a6969%2fannounce&tr=http%3a%2f%2ftracker.openbittorrent.com%3a80%2fannounce&tr=udp%3a%2f%2ftracker.tiny-vps.com%3a6969%2fannounce&tr=udp%3a%2f%2f9.rarbg.com%3a2810%2fannounce&tr=udp%3a%2f%2ftracker.monitorit4.me%3a6969%2fannounce&tr=udp%3a%2f%2ftracker.opentrackr.org%3a1337%2fannounce"}),"2023-04-01 torrent magnet")),(0,n.kt)("p",null,"!!! info ",(0,n.kt)("a",u({parentName:"p"},{href:"https://github.com/ggerganov/llama.cpp#interactive-mode"}),"Tutorial link for llama.cpp"),"\nGPT4 x Alpaca can be used with llama.cpp in the same way as the other ",(0,n.kt)("inlineCode",{parentName:"p"},"ggml")," models.\nText generation with this version is faster compared to the ",(0,n.kt)("a",u({parentName:"p"},{href:"https://rentry.org/nur779#gpt4-x-alpaca-13b-quantized-4-bit-weights-ggml-q4_1-from-gptq-with-groupsize-128"}),"GPTQ-quantized one"),".\n!!! info ",(0,n.kt)("a",u({parentName:"p"},{href:"https://github.com/LostRuins/koboldcpp#usage"}),"Tutorial link for koboldcpp")),(0,n.kt)("p",null,"SHA256 checksum:"),(0,n.kt)("pre",null,(0,n.kt)("code",u({parentName:"pre"},{className:"language-text"}),"e6b77ebf297946949b25b3c4b870f10cdc98fb9fcaa6d19cef4dda9021031580  gpt4-x-alpaca-13b-ggml-q4_0/ggml-model-q4_0.bin\n")),(0,n.kt)("p",null,"ggml model file magic: ",(0,n.kt)("inlineCode",{parentName:"p"},"0x67676a74")," (",(0,n.kt)("inlineCode",{parentName:"p"},"ggjt")," in hex)\nggml model file version: ",(0,n.kt)("inlineCode",{parentName:"p"},"1")),(0,n.kt)("p",null,(0,n.kt)("a",u({parentName:"p"},{href:"https://desuarchive.org/g/thread/92479457/#q92481589"}),"Model source")),(0,n.kt)("h2",u({},{id:"gpt4-x-alpaca-13b-quantized-4-bit-weights-ggml-q4_1-from-gptq-with-groupsize-128"}),"GPT4 x Alpaca 13B quantized 4-bit weights (ggml q4_1 from GPTQ with groupsize 128)"),(0,n.kt)("h4",u({},{id:"2023-04-01-torrent-magnet-1"}),(0,n.kt)("a",u({parentName:"h4"},{href:"magnet:?xt=urn:btih:6cdb6ab819b13b00928182eea72106824e335734&dn=GPT4-x-Alpaca-13B-ggml-4bit-from-GPTQ-128g_2023-04-01&tr=udp%3a%2f%2ftracker-udp.gbitt.info%3a80%2fannounce&tr=udp%3a%2f%2ftracker.torrent.eu.org%3a451%2fannounce&tr=udp%3a%2f%2ftracker.dler.org%3a6969%2fannounce&tr=udp%3a%2f%2ftracker.moeking.me%3a6969%2fannounce&tr=udp%3a%2f%2ftracker.tiny-vps.com%3a6969%2fannounce&tr=udp%3a%2f%2ftracker.openbittorrent.com%3a6969%2fannounce&tr=udp%3a%2f%2fopentracker.i2p.rocks%3a6969%2fannounce&tr=udp%3a%2f%2ftracker.altrosky.nl%3a6969%2fannounce&tr=udp%3a%2f%2ftracker.theoks.net%3a6969%2fannounce&tr=https%3a%2f%2fopentracker.i2p.rocks%3a443%2fannounce&tr=udp%3a%2f%2ftracker.opentrackr.org%3a1337%2fannounce&tr=udp%3a%2f%2f9.rarbg.com%3a2810%2fannounce&tr=udp%3a%2f%2ftracker1.bt.moack.co.kr%3a80%2fannounce&tr=udp%3a%2f%2ftracker.monitorit4.me%3a6969%2fannounce&tr=udp%3a%2f%2ftracker2.dler.org%3a80%2fannounce&tr=http%3a%2f%2ftracker.openbittorrent.com%3a80%2fannounce"}),"2023-04-01 torrent magnet")),(0,n.kt)("p",null,"!!! info ",(0,n.kt)("a",u({parentName:"p"},{href:"https://github.com/ggerganov/llama.cpp#interactive-mode"}),"Tutorial link for llama.cpp"),"\nGPT4 x Alpaca can be used with llama.cpp in the same way as the other ",(0,n.kt)("inlineCode",{parentName:"p"},"ggml")," models.\n!!! info ",(0,n.kt)("a",u({parentName:"p"},{href:"https://github.com/LostRuins/koboldcpp#usage"}),"Tutorial link for koboldcpp")),(0,n.kt)("p",null,"SHA256 checksum:"),(0,n.kt)("pre",null,(0,n.kt)("code",u({parentName:"pre"},{className:"language-text"}),"d4a640a1ce33009c244a361c6f87733aacbc2bea90e84d3c304a4c8be2bdf22d  gpt4-x-alpaca-13b-ggml-q4_1-from-gptq-4bit-128g/ggml-model-q4_1.bin\n")),(0,n.kt)("p",null,"ggml model file magic: ",(0,n.kt)("inlineCode",{parentName:"p"},"0x67676a74")," (",(0,n.kt)("inlineCode",{parentName:"p"},"ggjt")," in hex)\nggml model file version: ",(0,n.kt)("inlineCode",{parentName:"p"},"1")),(0,n.kt)("p",null,(0,n.kt)("a",u({parentName:"p"},{href:"https://desuarchive.org/g/thread/92479457/#q92481589"}),"Model source")),(0,n.kt)("h2",u({},{id:"vicuna-13b-quantized-4-bit-weights-ggml-q4_0"}),"Vicuna 13B quantized 4-bit weights (ggml q4_0)"),(0,n.kt)("h4",u({},{id:"2023-04-03-torrent-magnet"}),(0,n.kt)("a",u({parentName:"h4"},{href:"magnet:?xt=urn:btih:1e0c3dbeefe82483f81bd4e7ea959e4953c8081f&dn=Vicuna-13B-ggml-4bit-delta-merged_2023-04-03&tr=udp%3a%2f%2ftracker.opentrackr.org%3a1337%2fannounce&tr=udp%3a%2f%2f9.rarbg.com%3a2810%2fannounce&tr=udp%3a%2f%2ftracker.monitorit4.me%3a6969%2fannounce&tr=udp%3a%2f%2ftracker2.dler.org%3a80%2fannounce&tr=udp%3a%2f%2fopentracker.i2p.rocks%3a6969%2fannounce&tr=udp%3a%2f%2ftracker.torrent.eu.org%3a451%2fannounce&tr=udp%3a%2f%2ftracker.openbittorrent.com%3a6969%2fannounce&tr=udp%3a%2f%2ftracker.dler.org%3a6969%2fannounce&tr=udp%3a%2f%2ftracker-udp.gbitt.info%3a80%2fannounce&tr=udp%3a%2f%2ftracker1.bt.moack.co.kr%3a80%2fannounce&tr=https%3a%2f%2fopentracker.i2p.rocks%3a443%2fannounce&tr=udp%3a%2f%2ftracker.altrosky.nl%3a6969%2fannounce&tr=udp%3a%2f%2ftracker.tiny-vps.com%3a6969%2fannounce&tr=udp%3a%2f%2ftracker.moeking.me%3a6969%2fannounce&tr=http%3a%2f%2ftracker.openbittorrent.com%3a80%2fannounce&tr=udp%3a%2f%2ftracker.theoks.net%3a6969%2fannounce"}),"2023-04-03 torrent magnet")),(0,n.kt)("p",null,"!!! info ",(0,n.kt)("a",u({parentName:"p"},{href:"https://github.com/ggerganov/llama.cpp#interactive-mode"}),"Tutorial link for llama.cpp"),"\nVicuna can be used with llama.cpp in the same way as the other ",(0,n.kt)("inlineCode",{parentName:"p"},"ggml")," models.\n!!! info ",(0,n.kt)("a",u({parentName:"p"},{href:"https://github.com/LostRuins/koboldcpp#usage"}),"Tutorial link for koboldcpp")),(0,n.kt)("p",null,"SHA256 checksum:"),(0,n.kt)("pre",null,(0,n.kt)("code",u({parentName:"pre"},{className:"language-text"}),"f96689a13c581f53b616887b2efe82bbfbc5321258dbcfdbe69a22076a7da461  vicuna-13b-ggml-q4_0-delta-merged/ggml-model-q4_0.bin\n")),(0,n.kt)("p",null,"ggml model file magic: ",(0,n.kt)("inlineCode",{parentName:"p"},"0x67676a74")," (",(0,n.kt)("inlineCode",{parentName:"p"},"ggjt")," in hex)\nggml model file version: ",(0,n.kt)("inlineCode",{parentName:"p"},"1")),(0,n.kt)("p",null,(0,n.kt)("a",u({parentName:"p"},{href:"https://huggingface.co/lmsys/vicuna-13b-delta/tree/da39ef5c586459f4d509bf7382475af584277e71"}),"Model source")),(0,n.kt)("h2",u({},{id:"openassistant-llama-13b-quantized-4-bit-weights-ggml-q4_0--q4_1"}),"OpenAssistant LLaMA 13B quantized 4-bit weights (ggml q4_0 & q4_1)"),(0,n.kt)("p",null,"!!! warning Note that this model is ",(0,n.kt)("a",u({parentName:"p"},{href:"https://huggingface.co/dvruette/oasst-llama-13b-2-epochs/discussions/1#642ec79032e711e21aa11b60"}),"work-in-progress"),"."),(0,n.kt)("h4",u({},{id:"2023-04-07-torrent-magnet--huggingface-hub-direct-download"}),(0,n.kt)("a",u({parentName:"h4"},{href:"magnet:?xt=urn:btih:cad2f029978033f9c1487df3965546cc4d44489a&xt=urn:btmh:1220140702f43fbf90157db9531ad0454020bc212fddc48c7c30f593ec40d26eb19b&dn=oasst-llama-13b-ggml&tr=udp%3a%2f%2ftracker.opentrackr.org%3a1337%2fannounce&tr=udp%3a%2f%2f9.rarbg.com%3a2810%2fannounce&tr=udp%3a%2f%2ftracker.monitorit4.me%3a6969%2fannounce&tr=udp%3a%2f%2ftracker2.dler.org%3a80%2fannounce&tr=udp%3a%2f%2fopentracker.i2p.rocks%3a6969%2fannounce&tr=udp%3a%2f%2ftracker.torrent.eu.org%3a451%2fannounce&tr=udp%3a%2f%2ftracker.openbittorrent.com%3a6969%2fannounce&tr=udp%3a%2f%2ftracker.dler.org%3a6969%2fannounce&tr=udp%3a%2f%2ftracker-udp.gbitt.info%3a80%2fannounce&tr=udp%3a%2f%2ftracker1.bt.moack.co.kr%3a80%2fannounce&tr=https%3a%2f%2fopentracker.i2p.rocks%3a443%2fannounce&tr=udp%3a%2f%2ftracker.altrosky.nl%3a6969%2fannounce&tr=udp%3a%2f%2ftracker.tiny-vps.com%3a6969%2fannounce&tr=udp%3a%2f%2ftracker.moeking.me%3a6969%2fannounce&tr=http%3a%2f%2ftracker.openbittorrent.com%3a80%2fannounce&tr=udp%3a%2f%2ftracker.theoks.net%3a6969%2fannounce"}),"2023-04-07 torrent magnet")," | ",(0,n.kt)("a",u({parentName:"h4"},{href:"https://huggingface.co/Black-Engineer/oasst-llama13b-ggml-q4/tree/main"}),"HuggingFace Hub direct download")),(0,n.kt)("p",null,"!!! info ",(0,n.kt)("a",u({parentName:"p"},{href:"https://github.com/ggerganov/llama.cpp#interactive-mode"}),"Tutorial link for llama.cpp"),"\n!!! info ",(0,n.kt)("a",u({parentName:"p"},{href:"https://github.com/LostRuins/koboldcpp#usage"}),"Tutorial link for koboldcpp")),(0,n.kt)("p",null,"SHA256 checksums:"),(0,n.kt)("pre",null,(0,n.kt)("code",u({parentName:"pre"},{className:"language-text"}),"fe77206c7890ecd0824c7b6b6a6deab92e471366b2e4271c05ece9a686474ef6  ggml-model-q4_0.bin\n412da683b6ab0f710ce0adc8bc36db52bb92df96698558c5f2a1399af9bd0a78  ggml-model-q4_1.bin\n")),(0,n.kt)("p",null,"ggml model file magic: ",(0,n.kt)("inlineCode",{parentName:"p"},"0x67676a74")," (",(0,n.kt)("inlineCode",{parentName:"p"},"ggjt")," in hex)\nggml model file version: ",(0,n.kt)("inlineCode",{parentName:"p"},"1")),(0,n.kt)("p",null,(0,n.kt)("a",u({parentName:"p"},{href:"https://huggingface.co/dvruette/oasst-llama-13b-2-epochs"}),"Original model source"),"\n",(0,n.kt)("a",u({parentName:"p"},{href:"https://huggingface.co/gozfarb/oasst-llama13b-4bit-128g"}),"GPTQ-quantized model source"),"\n",(0,n.kt)("a",u({parentName:"p"},{href:"https://desuarchive.org/g/thread/92596368/#q92601864"}),"Torrent source")),(0,n.kt)("hr",null),(0,n.kt)("h1",u({},{id:"models-for-huggingface-"}),"Models for HuggingFace \ud83e\udd17"),(0,n.kt)("p",null,"!!! danger Updated tokenizer and model configuration files can be found ",(0,n.kt)("a",u({parentName:"p"},{href:"https://rentry.org/544p2"}),"here"),".\nEnsure that your models have the appropriate JSON files within the same directory as the weights, otherwise text generation might be impacted by tokenization problems. The issues were addressed ",(0,n.kt)("a",u({parentName:"p"},{href:"https://github.com/huggingface/transformers/pull/22402"}),"here")," and ",(0,n.kt)("a",u({parentName:"p"},{href:"https://github.com/lm-sys/FastChat/pull/167"}),"here"),", but a manual update of both the ",(0,n.kt)("inlineCode",{parentName:"p"},"transformers")," library and your model configuration files is required."),(0,n.kt)("h2",u({},{id:"llama-float16-weights"}),"LLaMA float16 weights"),(0,n.kt)("h4",u({},{id:"2023-03-26-torrent-magnet--huggingface-hub-direct-downloads"}),(0,n.kt)("a",u({parentName:"h4"},{href:"magnet:?xt=urn:btih:496ee41a35f8d845f6d6cba11baa8b332f3c3318&dn=Safe-LLaMA-HF%20(3-26-23)&tr=http%3a%2f%2fbt2.archive.org%3a6969%2fannounce&tr=http%3a%2f%2fbt1.archive.org%3a6969%2fannounce"}),"2023-03-26 torrent magnet")," | ",(0,n.kt)("a",u({parentName:"h4"},{href:"https://huggingface.co/Neko-Institute-of-Science"}),"HuggingFace Hub direct downloads")),(0,n.kt)("p",null,"!!! info ",(0,n.kt)("a",u({parentName:"p"},{href:"https://github.com/oobabooga/text-generation-webui/wiki/LLaMA-model#hugging-face-format-weights"}),"Tutorial link for Text generation web UI")),(0,n.kt)("p",null,(0,n.kt)("a",u({parentName:"p"},{href:"https://github.com/oobabooga/text-generation-webui/pull/530#issuecomment-1484235789"}),"Torrent source and SHA256 checksums")),(0,n.kt)("h2",u({},{id:"vicuna-13b-float16-weights"}),"Vicuna 13B float16 weights"),(0,n.kt)("h4",u({},{id:"2023-04-03-torrent-magnet-1"}),(0,n.kt)("a",u({parentName:"h4"},{href:"magnet:?xt=urn:btih:a7fac57094561a63d53eed943f904abf24c6969d&dn=Vicuna-13B-HF-fp16-delta-merged_2023-04-03&tr=udp%3a%2f%2ftracker.opentrackr.org%3a1337%2fannounce&tr=udp%3a%2f%2ftracker-udp.gbitt.info%3a80%2fannounce&tr=udp%3a%2f%2ftracker1.bt.moack.co.kr%3a80%2fannounce&tr=udp%3a%2f%2ftracker.tiny-vps.com%3a6969%2fannounce&tr=udp%3a%2f%2ftracker2.dler.org%3a80%2fannounce&tr=udp%3a%2f%2fopentracker.i2p.rocks%3a6969%2fannounce&tr=udp%3a%2f%2ftracker.altrosky.nl%3a6969%2fannounce&tr=udp%3a%2f%2ftracker.theoks.net%3a6969%2fannounce&tr=udp%3a%2f%2ftracker.dler.org%3a6969%2fannounce&tr=udp%3a%2f%2ftracker.torrent.eu.org%3a451%2fannounce&tr=udp%3a%2f%2ftracker.openbittorrent.com%3a6969%2fannounce&tr=https%3a%2f%2fopentracker.i2p.rocks%3a443%2fannounce&tr=http%3a%2f%2ftracker.openbittorrent.com%3a80%2fannounce&tr=udp%3a%2f%2ftracker.moeking.me%3a6969%2fannounce&tr=udp%3a%2f%2ftracker.monitorit4.me%3a6969%2fannounce&tr=udp%3a%2f%2f9.rarbg.com%3a2810%2fannounce"}),"2023-04-03 torrent magnet")),(0,n.kt)("p",null,"!!! info ",(0,n.kt)("a",u({parentName:"p"},{href:"https://github.com/oobabooga/text-generation-webui/wiki/LLaMA-model#hugging-face-format-weights"}),"Tutorial link for Text generation web UI")),(0,n.kt)("p",null,(0,n.kt)("a",u({parentName:"p"},{href:"https://huggingface.co/lmsys/vicuna-13b-delta/tree/da39ef5c586459f4d509bf7382475af584277e71"}),"Model source")),(0,n.kt)("h2",u({},{id:"llama-quantized-4-bit-weights-gptq-format-without-groupsize"}),"LLaMA quantized 4-bit weights (",(0,n.kt)("a",u({parentName:"h2"},{href:"https://github.com/qwopqwop200/GPTQ-for-LLaMa"}),"GPTQ")," format without groupsize)"),(0,n.kt)("h4",u({},{id:"2023-03-26-torrent-magnet"}),(0,n.kt)("a",u({parentName:"h4"},{href:"magnet:?xt=urn:btih:e88abf1b84290b162f00d3a9d79fb4f8719c2053&dn=LLaMA-HF-4bit&tr=http%3a%2f%2fbt2.archive.org%3a6969%2fannounce&tr=http%3a%2f%2fbt1.archive.org%3a6969%2fannounce"}),"2023-03-26 torrent magnet")),(0,n.kt)("p",null,"!!! info ",(0,n.kt)("a",u({parentName:"p"},{href:"https://github.com/oobabooga/text-generation-webui/wiki/LLaMA-model#4-bit-mode"}),"Tutorial link for Text generation web UI")),(0,n.kt)("p",null,"SHA256 checksums:"),(0,n.kt)("pre",null,(0,n.kt)("code",u({parentName:"pre"},{className:"language-text"}),"09841a1c4895e1da3b05c1bdbfb8271c6d43812661e4348c862ff2ab1e6ff5b3  llama-7b-4bit/llama-7b-4bit.safetensors\nedfa0b4060aae392b1e9df21fb60a97d78c9268ac6972e3888f6dc955ba0377b  llama-13b-4bit/llama-13b-4bit.safetensors\n4cb560746fe58796233159612d8d3c9dbdebdf6f0443b47be71643f2f91b8541  llama-30b-4bit/llama-30b-4bit.safetensors\n886ce814ed54c4bd6850e2216d5f198c49475210f8690f45dc63365d9aff3177  llama-65b-4bit/llama-65b-4bit.safetensors\n")),(0,n.kt)("p",null,(0,n.kt)("a",u({parentName:"p"},{href:"https://github.com/oobabooga/text-generation-webui/pull/530#issuecomment-1483891617"}),"Torrent source and more information")),(0,n.kt)("h2",u({},{id:"llama-quantized-4-bit-weights-gptq-format-with-groupsize-128"}),"LLaMA quantized 4-bit weights (",(0,n.kt)("a",u({parentName:"h2"},{href:"https://github.com/qwopqwop200/GPTQ-for-LLaMa"}),"GPTQ")," format with groupsize 128)"),(0,n.kt)("h4",u({},{id:"2023-03-26-torrent-magnet-1"}),(0,n.kt)("a",u({parentName:"h4"},{href:"magnet:?xt=urn:btih:88f7d9d2460ffcaf78b21e83012de00939eacb65&dn=LLaMA-HF-4bit-128g&tr=http%3a%2f%2fbt2.archive.org%3a6969%2fannounce&tr=http%3a%2f%2fbt1.archive.org%3a6969%2fannounce"}),"2023-03-26 torrent magnet")),(0,n.kt)("p",null,"!!! info ",(0,n.kt)("a",u({parentName:"p"},{href:"https://github.com/oobabooga/text-generation-webui/wiki/LLaMA-model#4-bit-mode"}),"Tutorial link for Text generation web UI"),"\n",(0,n.kt)("inlineCode",{parentName:"p"},"Groupsize 128")," is a better choice for the 13B, 33B and 65B models, according to ",(0,n.kt)("a",u({parentName:"p"},{href:"https://github.com/oobabooga/text-generation-webui/pull/530#issuecomment-1483941105"}),"this"),"."),(0,n.kt)("p",null,"SHA256 checksums:"),(0,n.kt)("pre",null,(0,n.kt)("code",u({parentName:"pre"},{className:"language-text"}),"ed8ec9c9f0ebb83210157ad0e3c5148760a4e9fd2acfb02cf00f8f2054d2743b  llama-7b-4bit-128g/llama-7b-4bit-128g.safetensors\nd3073ef1a2c0b441f95a5d4f8a5aa3b82884eef45d8997270619cb29bcc994b8  llama-13b-4bit-128g/llama-13b-4bit-128g.safetensors\n8b7d75d562938823c4503b956cb4b8af6ac0a5afbce2278566cc787da0f8f682  llama-30b-4bit-128g/llama-30b-4bit-128g.safetensors\nf1418091e3307611fb0a213e50a0f52c80841b9c4bcba67abc1f6c64c357c850  llama-65b-4bit-128g/llama-65b-4bit-128g.safetensors\n")),(0,n.kt)("p",null,(0,n.kt)("a",u({parentName:"p"},{href:"https://github.com/oobabooga/text-generation-webui/pull/530#issuecomment-1483941105"}),"Torrent source and more information")),(0,n.kt)("h2",u({},{id:"alpaca-quantized-4-bit-weights-gptq-format-with-groupsize-128"}),"Alpaca quantized 4-bit weights (",(0,n.kt)("a",u({parentName:"h2"},{href:"https://github.com/qwopqwop200/GPTQ-for-LLaMa"}),"GPTQ")," format with groupsize 128)"),(0,n.kt)("table",null,(0,n.kt)("thead",{parentName:"table"},(0,n.kt)("tr",{parentName:"thead"},(0,n.kt)("th",u({parentName:"tr"},{align:null}),"Model"),(0,n.kt)("th",u({parentName:"tr"},{align:null}),"Download"))),(0,n.kt)("tbody",{parentName:"table"},(0,n.kt)("tr",{parentName:"tbody"},(0,n.kt)("td",u({parentName:"tr"},{align:null}),"LLaMA 7B fine-tune from ",(0,n.kt)("a",u({parentName:"td"},{href:"https://huggingface.co/ozcur/alpaca-native-4bit"}),"ozcur/alpaca-native-4bit")," as safetensors"),(0,n.kt)("td",u({parentName:"tr"},{align:null}),(0,n.kt)("a",u({parentName:"td"},{href:"magnet:?xt=urn:btih:90674fd4a3672c6eae5bf994634109bb75429e6b&dn=Alpaca-7B-GPTQ-4bit-128g-native-finetune_2023-03-29&tr=udp%3a%2f%2fopentracker.i2p.rocks%3a6969%2fannounce&tr=udp%3a%2f%2ftracker.altrosky.nl%3a6969%2fannounce&tr=udp%3a%2f%2ftracker-udp.gbitt.info%3a80%2fannounce&tr=udp%3a%2f%2ftracker.opentrackr.org%3a1337%2fannounce&tr=udp%3a%2f%2ftracker.skynetcloud.site%3a6969%2fannounce&tr=udp%3a%2f%2ftracker2.dler.org%3a80%2fannounce&tr=udp%3a%2f%2ftracker.monitorit4.me%3a6969%2fannounce&tr=udp%3a%2f%2ftracker.lelux.fi%3a6969%2fannounce&tr=udp%3a%2f%2ftracker1.bt.moack.co.kr%3a80%2fannounce&tr=udp%3a%2f%2ftracker.torrent.eu.org%3a451%2fannounce&tr=udp%3a%2f%2f9.rarbg.com%3a2810%2fannounce&tr=udp%3a%2f%2ftracker.theoks.net%3a6969%2fannounce&tr=udp%3a%2f%2ftracker.moeking.me%3a6969%2fannounce&tr=udp%3a%2f%2ftracker.tiny-vps.com%3a6969%2fannounce&tr=udp%3a%2f%2ftracker.openbittorrent.com%3a6969%2fannounce&tr=http%3a%2f%2ftracker.openbittorrent.com%3a80%2fannounce&tr=udp%3a%2f%2ftracker.dler.org%3a6969%2fannounce&tr=https%3a%2f%2fopentracker.i2p.rocks%3a443%2fannounce"}),"2023-03-29 torrent magnet"))),(0,n.kt)("tr",{parentName:"tbody"},(0,n.kt)("td",u({parentName:"tr"},{align:null}),"LLaMA 33B merged with ",(0,n.kt)("a",u({parentName:"td"},{href:"https://huggingface.co/baseten/alpaca-30b"}),"baseten/alpaca-30b")," LoRA by ",(0,n.kt)("a",u({parentName:"td"},{href:"https://desuarchive.org/g/thread/92351574/#q92356537"}),"an anon")),(0,n.kt)("td",u({parentName:"tr"},{align:null}),(0,n.kt)("a",u({parentName:"td"},{href:"magnet:?xt=urn:btih:81cf9b528cc80e390323f9ec50d4dfb4debcb490&dn=Alpaca%2030B%204bit%20groupsize%20128&tr=http%3A%2F%2Fbt2.archive.org%3A6969%2Fannounce"}),"2023-03-26 torrent magnet")," ","|"," ",(0,n.kt)("a",u({parentName:"td"},{href:"https://rentry.org/544p2#llama-33b"}),"extra config files"))))),(0,n.kt)("p",null,"!!! info ",(0,n.kt)("a",u({parentName:"p"},{href:"https://github.com/oobabooga/text-generation-webui/wiki/LLaMA-model#4-bit-mode"}),"Tutorial link for Text generation web UI")),(0,n.kt)("p",null,"SHA256 checksums:"),(0,n.kt)("pre",null,(0,n.kt)("code",u({parentName:"pre"},{className:"language-text"}),"17d6ba8f83be89f8dfa05cd4720cdd06b4d32c3baed79986e3ba1501b2305530  Alpaca-7B-GPTQ-4bit-128g-native-finetune_2023-03-29/alpaca-7b-4bit-128g-native-finetune.safetensors\na2f8d202ce61b1b612afe08c11f97133c1d56076d65391e738b1ab57c854ee05  Alpaca-30B-4bit-128g/alpaca-30b-hf-4bit.safetensors\n")),(0,n.kt)("h2",u({},{id:"vicuna-13b-quantized-4-bit--8-bit-weights-gptq-format-with-groupsize-128"}),"Vicuna 13B quantized 4-bit & 8-bit weights (",(0,n.kt)("a",u({parentName:"h2"},{href:"https://github.com/qwopqwop200/GPTQ-for-LLaMa"}),"GPTQ")," format with groupsize 128)"),(0,n.kt)("h5",u({},{id:"2023-04-03-torrent-magnet-2"}),(0,n.kt)("a",u({parentName:"h5"},{href:"magnet:?xt=urn:btih:f67d372a01c0b8e0162931623d6c55a5e6f34921&dn=Vicuna-13B-quantized-128g&tr=http%3a%2f%2fbt2.archive.org%3a6969%2fannounce"}),"2023-04-03 torrent magnet")),(0,n.kt)("p",null,"!!! info ",(0,n.kt)("a",u({parentName:"p"},{href:"https://github.com/oobabooga/text-generation-webui/wiki/LLaMA-model#4-bit-mode"}),"Tutorial link for Text generation web UI")),(0,n.kt)("p",null,(0,n.kt)("a",u({parentName:"p"},{href:"https://desuarchive.org/g/thread/92531914#92536953"}),"Torrent source"),"\n",(0,n.kt)("a",u({parentName:"p"},{href:"https://rentry.org/544p2#llama-13b"}),"Extra config files")))}h.isMDXComponent=!0}}]);